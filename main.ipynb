{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86efa528",
   "metadata": {},
   "source": [
    "## 参考文献 XML → 参考文献文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a3b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 李晓东, 张庆红, 叶瑾琳. 气候学研究的若干理论问题[J]. 北京大学学报(自然科学版), 1999,35(1): 101-106.\n",
      "[2] 余敏. 出版集团研究[M]. 北京, 中国书籍出版社, 2001: 179-193.\n",
      "[3] 萧钰. 出版业信息化迈入快车道[EB/OL]. 2001[2023-03-06]. http://www.creader.com/news/20011219/200112190019.html.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "TYPE_LABEL = {\n",
    "    \"journal\": \"J\", \"book\": \"M\", \"conference\": \"C\",\n",
    "    \"web\": \"EB/OL\", \"patent\": \"P\", \"thesis\": \"D\",\n",
    "    \"report\": \"R\", \"standard\": \"S\", \"newspaper\": \"N\"\n",
    "}\n",
    "\n",
    "def pick_text(parent, tag, default=\"\"):\n",
    "    e = parent.find(tag)\n",
    "    return (e.text or \"\").strip() if e is not None else default\n",
    "\n",
    "def format_creators(creators):\n",
    "    names = [c.text.strip() for c in creators if c.text]\n",
    "    if len(names) > 3:\n",
    "        return \", \".join(names[:3]) + \", 等\"\n",
    "    return \", \".join(names)\n",
    "\n",
    "def build_journal_line(ref):\n",
    "    creators = ref.findall(\"r-creator\")\n",
    "    title = pick_text(ref, \"r-title\")\n",
    "    subtitle = pick_text(ref, \"r-subtitle\")\n",
    "    if subtitle:\n",
    "        title += f\": {subtitle}\"\n",
    "\n",
    "    pub = ref.find(\"r-publication\")\n",
    "    journal = pick_text(pub, \"r-publisher\")\n",
    "    year = pick_text(pub, \"r-year\")\n",
    "    vol = pick_text(pub, \"r-volume\")\n",
    "    iss = pick_text(pub, \"r-issue\")\n",
    "    pages = pick_text(ref, \"r-pages\")\n",
    "\n",
    "    line = f\"{format_creators(creators)}. {title}[J]. {journal}\"\n",
    "    if year or vol or iss:\n",
    "        line += f\", {year}\"\n",
    "        if vol:\n",
    "            line += f\",{vol}\"\n",
    "        if iss:\n",
    "            line += f\"({iss})\"\n",
    "    if pages:\n",
    "        line += f\": {pages}\"\n",
    "    return line + \".\"\n",
    "\n",
    "def build_book_line(ref):\n",
    "    creators = ref.findall(\"r-creator\")\n",
    "    title = pick_text(ref, \"r-title\")\n",
    "    subtitle = pick_text(ref, \"r-subtitle\")\n",
    "    if subtitle:\n",
    "        title += f\": {subtitle}\"\n",
    "\n",
    "    edition = pick_text(ref, \"r-edition\")\n",
    "    pub = ref.find(\"r-publication\")\n",
    "    place = pick_text(pub, \"r-place\")\n",
    "    publisher = pick_text(pub, \"r-publisher\")\n",
    "    year = pick_text(pub, \"r-year\")\n",
    "    pages = pick_text(ref, \"r-pages\")\n",
    "\n",
    "    line = f\"{format_creators(creators)}. {title}[M]\"\n",
    "    if edition:\n",
    "        line += f\". {edition}\"\n",
    "    pub_part = \", \".join(filter(None, [place, publisher]))\n",
    "    if pub_part:\n",
    "        line += f\". {pub_part}\"\n",
    "    if year:\n",
    "        line += f\", {year}\"\n",
    "    if pages:\n",
    "        line += f\": {pages}\"\n",
    "    return line + \".\"\n",
    "\n",
    "def build_web_line(ref):\n",
    "    creators = ref.findall(\"r-creator\")\n",
    "    title = pick_text(ref, \"r-title\")\n",
    "    year = pick_text(ref.find(\"r-publication\"), \"r-year\")\n",
    "    url = pick_text(ref, \"r-url\")\n",
    "    accessed = pick_text(ref, \"r-accessed\")\n",
    "\n",
    "    line = f\"{format_creators(creators)}. {title}[EB/OL]\"\n",
    "    if year:\n",
    "        line += f\". {year}\"\n",
    "    if accessed:\n",
    "        line += f\"[{accessed}]\"\n",
    "    if url:\n",
    "        line += f\". {url}\"\n",
    "    return line + \".\"\n",
    "\n",
    "def format_ref(ref):\n",
    "    t = ref.get(\"type\", \"\")\n",
    "    if t == \"journal\":\n",
    "        return build_journal_line(ref)\n",
    "    if t in {\"book\", \"thesis\", \"report\", \"standard\"}:\n",
    "        return build_book_line(ref)\n",
    "    if t in {\"web\", \"newspaper\"}:\n",
    "        return build_web_line(ref)\n",
    "    # 其他类型可按需扩展\n",
    "    return f\"<!-- type {t} not implemented -->\"\n",
    "\n",
    "def xml2gbt(xml_str: str) -> List[str]:\n",
    "    root = ET.fromstring(xml_str)\n",
    "    refs = root.findall(\"r-ref\")\n",
    "    return [f\"[{idx}] {format_ref(r)}\" for idx, r in enumerate(refs, 1)]\n",
    "\n",
    "# ---------- 5. 命令行 ----------\n",
    "if __name__ == \"__main__\":\n",
    "    demo_xml = \"\"\"\n",
    "    <r-refs>\n",
    "      <r-ref id=\"1\" type=\"journal\">\n",
    "        <r-creator>李晓东</r-creator>\n",
    "        <r-creator>张庆红</r-creator>\n",
    "        <r-creator>叶瑾琳</r-creator>\n",
    "        <r-title>气候学研究的若干理论问题</r-title>\n",
    "        <r-publication>\n",
    "          <r-publisher>北京大学学报(自然科学版)</r-publisher>\n",
    "          <r-year>1999</r-year>\n",
    "          <r-volume>35</r-volume>\n",
    "          <r-issue>1</r-issue>\n",
    "        </r-publication>\n",
    "        <r-pages>101-106</r-pages>\n",
    "      </r-ref>\n",
    "\n",
    "      <r-ref id=\"2\" type=\"book\">\n",
    "        <r-creator>余敏</r-creator>\n",
    "        <r-title>出版集团研究</r-title>\n",
    "        <r-publication>\n",
    "          <r-place>北京</r-place>\n",
    "          <r-publisher>中国书籍出版社</r-publisher>\n",
    "          <r-year>2001</r-year>\n",
    "        </r-publication>\n",
    "        <r-pages>179-193</r-pages>\n",
    "      </r-ref>\n",
    "\n",
    "      <r-ref id=\"3\" type=\"web\">\n",
    "        <r-creator>萧钰</r-creator>\n",
    "        <r-title>出版业信息化迈入快车道</r-title>\n",
    "        <r-publication>\n",
    "          <r-year>2001</r-year>\n",
    "        </r-publication>\n",
    "        <r-url>http://www.creader.com/news/20011219/200112190019.html</r-url>\n",
    "        <r-accessed>2023-03-06</r-accessed>\n",
    "      </r-ref>\n",
    "    </r-refs>\n",
    "    \"\"\"\n",
    "    for line in xml2gbt(demo_xml):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4450578",
   "metadata": {},
   "source": [
    "## 生成框架（使用长思考）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf0adff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤔 Thinking...\n",
      "\n",
      "我 need to create a structured outline for a literature review on the topic \"LSTM 的拓展应用\" in Simplified Chinese. The outline should cover research background, gaps in current research, main research directions, and regional comparisons. I'll use the provided XML structure to format my response.\n",
      "\n",
      "First, I'll think through each section:\n",
      "\n",
      "1. Title: I need to create a targeted title that reflects the focus on LSTM's extended applications. Something like \"LSTM 拓展应用的前沿研究与实践探索\" (Frontier Research and Practical Exploration of LSTM Extended Applications) could work.\n",
      "\n",
      "2. Research Background:\n",
      "   - Research Status: I'll provide a brief overview of LSTM's current applications, mentioning its use in time series prediction, natural language processing, speech recognition, etc.\n",
      "   - Literature Map: I'll describe the main themes like LSTM variants, application domains, and integration with other technologies.\n",
      "\n",
      "3. Research Gaps:\n",
      "   - I'll identify major gaps such as LSTM's limitations in handling long-term dependencies, computational efficiency issues, and lack of interpretability in complex models.\n",
      "\n",
      "4. Main Directions:\n",
      "   - I'll outline primary research directions including model optimization, interdisciplinary applications, and hybrid model development. For each direction, I'll mention inherent limitations.\n",
      "\n",
      "5. Regional Comparison:\n",
      "   - I'll summarize domestic (Chinese) research focusing on practical applications and international research emphasizing theoretical innovations and interdisciplinary approaches.\n",
      "\n",
      "Now, I'll structure this into the required XML format with placeholder content for each section. I'll make sure the content is concise but informative enough to guide further research and writing.<framework>\n",
      "<f-title>LSTM 拓展应用的前沿研究与实践探索</f-title>\n",
      "<f-background>\n",
      "  <f-research-status>当前 LSTM 研究已广泛覆盖时间序列预测、自然语言处理、计算机视觉等多个领域，形成了包括双向 LSTM、深度 LSTM、注意力机制融合 LSTM 等多种变体。在智能交通流量预测、金融数据分析、医疗健康监测等方面有大量应用案例，但大部分研究仍集中在模型性能优化而非跨领域融合应用。</f-research-status>\n",
      "  <f-literature-map>主要研究主题包括 LSTM 架构改进（如门控机制优化）、与其他算法融合（如 CNN、Transformer）、特定领域应用开发（如语音识别、文本生成）。各主题间关系呈现从基础理论研究到行业应用拓展的层级结构，近年出现多模态数据处理与 LSTM 结合的新趋势。</f-literature-map>\n",
      "</f-background>\n",
      "<f-gaps>\n",
      "  <f-gap-1>现有研究在处理超长序列数据时，LSTM 仍存在梯度消失问题，尚未形成有效的通用解决方案，多数优化方法仅针对特定场景有效。</f-gap-1>\n",
      "  <f-gap-2>跨领域知识迁移应用不足，不同行业 LSTM 模型大多独立开发，缺乏可复用的知识体系和迁移学习框架，导致研发成本重复。</f-gap-2>\n",
      "  <f-gap-3>模型可解释性研究薄弱，特别是在复杂应用场景中，难以向非技术用户清晰解释 LSTM 决策逻辑，限制了其在关键决策领域的应用推广。</f-gap-3>\n",
      "</f-gaps>\n",
      "<f-directions>\n",
      "  <f-direction>\n",
      "    <f-scope>模型架构创新与性能优化，包括新型门控机制设计、计算效率提升、内存占用优化等方向，重点关注在移动终端和边缘计算设备上的轻量化部署。</f-scope>\n",
      "    <f-inherent-limitations>该方向可能面临理论瓶颈，现有计算框架对基础架构改动支持有限，且性能提升与模型复杂度增加存在矛盾关系。</f-inherent-limitations>\n",
      "  </f-direction>\n",
      "  <f-direction>\n",
      "    <f-scope>跨领域融合应用开发，探索 LSTM 在智慧城市、工业物联网、生物信息学等新兴领域的创新应用，注重多源异构数据处理能力。</f-scope>\n",
      "    <f-inherent-limitations>跨领域应用面临数据标准不统一、领域知识差异大等挑战，模型泛化能力与领域适配精度存在平衡难题。</f-inherent-limitations>\n",
      "  </f-direction>\n",
      "  <f-direction>\n",
      "    <f-scope>可解释性人工智能（XAI）与 LSTM 结合研究，开发面向不同用户群体的可视化解释工具，建立模型决策过程的透明度评估体系。</f-scope>\n",
      "    <f-inherent-limitations>可解释性增强可能以牺牲部分模型性能为代价，且不同解释方法在技术兼容性和用户体验上存在显著差异。</f-inherent-limitations>\n",
      "  </f-direction>\n",
      "</f-directions>\n",
      "<f-regional-comparison>\n",
      "  <f-domestic>国内研究侧重于应用开发和工程实现，在智能安防视频分析、移动支付风险预测、智能客服系统等领域有大量落地案例，研究团队以企业研发部门和应用型高校为主，发表论文多集中于国内期刊和应用类会议。</f-domestic>\n",
      "  <f-international>国际研究更注重基础理论创新和跨学科合作，欧美高校和研究机构在 LSTM 与神经科学、认知心理学交叉研究方面成果突出，亚洲地区（尤其是日本和韩国）在机器人控制、自动驾驶等领域的 LSTM 应用研究处于领先地位，论文发表多见于顶级学术会议和国际权威期刊。</f-international>\n",
      "</f-regional-comparison>\n",
      "</framework>"
     ]
    }
   ],
   "source": [
    "\n",
    "import openai, os, sys\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1. 配置\n",
    "MODEL = \"kimi-thinking-preview\"\n",
    "API_KEY = \"sk-ngwOcq4h7reY7qL7jQeOVkmZhWCg9Xh95ilq2NkXIsArpQRC\"\n",
    "BASE_URL = \"https://api.moonshot.cn/v1\"\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "\n",
    "# 2. 生成（完全流式）\n",
    "def gen_outline_stream(topic: str):\n",
    "    prompt = f\"\"\"\n",
    "You are tasked with creating a structured outline for a literature review on a given topic in Simplified Chinese. This outline will serve as a framework for further research and writing. Your goal is to generate a comprehensive structure that covers the research background, gaps in current research, main research directions, and regional comparisons. 使用简体中文进行思考。\n",
    "\n",
    "The topic for the literature review is given by user:\n",
    "<topic>\n",
    "{topic}\n",
    "</topic>\n",
    "\n",
    "Title should be determined according to needs and should be targeted to a certain extent, such as cutting-edge issues in disciplinary development, new achievements and new technologies in scientific research, hot social and economic issues, and practical problems in production practice.\n",
    "\n",
    "Before generating the final output, use a scratchpad to think through the structure and content for each section. Consider the following:\n",
    "- What is the current state of research on this topic?\n",
    "- What are the main gaps or limitations in existing research?\n",
    "- What are the primary research directions within this field?\n",
    "- How does research in this area differ between domestic and international contexts?\n",
    "\n",
    "Once you have thought through these elements, generate the outline using the following XML structure. Provide brief, placeholder content for each section to guide further research and writing:\n",
    "\n",
    "<framework>\n",
    "<f-title>{{Title}}</f-title>\n",
    "<!-- 3. Research Background (Abstract Framework) -->\n",
    "<f-background>\n",
    "  <f-research-status>\n",
    "    <!-- Provide a brief overview of the current research status -->\n",
    "  </f-research-status>\n",
    "  <f-literature-map>\n",
    "    <!-- Describe the main themes and relationships within the topic -->\n",
    "  </f-literature-map>\n",
    "</f-background>\n",
    "\n",
    "<!-- 4. Research Gaps (Abstract Framework) -->\n",
    "<f-gaps>\n",
    "  <f-gap-1>\n",
    "    <!-- Describe the first major gap in current research -->\n",
    "  </f-gap-1>\n",
    "  <f-gap-2>\n",
    "    <!-- Describe the second major gap in current research -->\n",
    "  </f-gap-2>\n",
    "  <!-- Add more gap elements if necessary -->\n",
    "</f-gaps>\n",
    "\n",
    "<!-- 5. Main Directions (Abstract Framework) -->\n",
    "<f-directions>\n",
    "  <f-direction>\n",
    "    <f-scope>\n",
    "      <!-- Name and describe the scope of the first main research direction -->\n",
    "    </f-scope>\n",
    "    <f-inherent-limitations>\n",
    "      <!-- Outline the inherent limitations of this research direction -->\n",
    "    </f-inherent-limitations>\n",
    "  </f-direction>\n",
    "  <!-- Add more direction elements if necessary -->\n",
    "</f-directions>\n",
    "\n",
    "<!-- 6. Regional Comparison (Abstract Framework) -->\n",
    "<f-regional-comparison>\n",
    "  <f-domestic>\n",
    "    <!-- Summarize the state of domestic research on the topic -->\n",
    "  </f-domestic>\n",
    "  <f-international>\n",
    "    <!-- Summarize the state of international research on the topic -->\n",
    "  </f-international>\n",
    "</f-regional-comparison>\n",
    "\n",
    "Ensure that each section contains relevant placeholder content that can guide further research and writing. The content should be concise yet informative, providing a clear direction for the literature review\n",
    "                        \n",
    "NOTE!!! It is strictly forbidden to output any other text outside the given XML framework!!!\n",
    "\"\"\"\n",
    "    print(\"🤔 Thinking...\\n\")\n",
    "    buffer = []                              # 用于收集完整正文\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=2048,\n",
    "        temperature=0.8,\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if hasattr(delta, \"reasoning_content\") and delta.reasoning_content:\n",
    "            # 如需查看推理过程可取消下行注释\n",
    "            print(delta.reasoning_content, end=\"\", flush=True)\n",
    "        if delta.content:\n",
    "            print(delta.content, end=\"\", flush=True)\n",
    "            buffer.append(delta.content)\n",
    "    full_text = \"\".join(buffer)\n",
    "    return full_text\n",
    "\n",
    "# 3. 运行\n",
    "if __name__ == \"__main__\":\n",
    "    topic = \"LSTM 的拓展应用\"\n",
    "    framework = gen_outline_stream(topic)\n",
    "    with open(\"framework.xml\", 'w', encoding='utf-8') as f:\n",
    "        f.write(framework)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e83126",
   "metadata": {},
   "source": [
    "## 生成完整材料（使用检索）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理框架文件: framework.xml\n",
      "框架解析完成，标题: LSTM 拓展应用的前沿研究与实践探索\n",
      "开始进行文献检索...\n",
      "检索研究现状...\n",
      "检索文献主题关系...\n",
      "检索研究空白 1...\n",
      "检索研究空白 2...\n",
      "检索研究空白 3...\n",
      "检索研究方向 1...\n",
      "检索研究方向 2...\n",
      "检索研究方向 3...\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from typing import Dict, List, Any\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# 设置客户端\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-ngwOcq4h7reY7qL7jQeOVkmZhWCg9Xh95ilq2NkXIsArpQRC\",\n",
    "    base_url=\"https://api.moonshot.cn/v1\"\n",
    ")\n",
    "\n",
    "MODEL = \"kimi-k2-0711-preview\"\n",
    "\n",
    "class ProgressBar:\n",
    "    def __init__(self, total_steps: int, width: int = 50):\n",
    "        self.total_steps = total_steps\n",
    "        self.current_step = 0\n",
    "        self.width = width\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def update(self, step_description: str = \"\"):\n",
    "        \"\"\"更新进度条\"\"\"\n",
    "        self.current_step += 1\n",
    "        progress = self.current_step / self.total_steps\n",
    "        filled_width = int(self.width * progress)\n",
    "        \n",
    "        # 计算已用时间和预估剩余时间\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        if self.current_step > 0:\n",
    "            avg_time_per_step = elapsed_time / self.current_step\n",
    "            remaining_steps = self.total_steps - self.current_step\n",
    "            eta = avg_time_per_step * remaining_steps\n",
    "        else:\n",
    "            eta = 0\n",
    "            \n",
    "        # 格式化时间显示\n",
    "        def format_time(seconds):\n",
    "            if seconds < 60:\n",
    "                return f\"{seconds:.0f}s\"\n",
    "            elif seconds < 3600:\n",
    "                return f\"{seconds//60:.0f}m{seconds%60:.0f}s\"\n",
    "            else:\n",
    "                return f\"{seconds//3600:.0f}h{(seconds%3600)//60:.0f}m\"\n",
    "        \n",
    "        # 构建进度条\n",
    "        bar = '█' * filled_width + '░' * (self.width - filled_width)\n",
    "        percentage = progress * 100\n",
    "        \n",
    "        # 清除当前行并打印新的进度条\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(f'进度: [{bar}] {percentage:.1f}% ({self.current_step}/{self.total_steps}) ')\n",
    "        sys.stdout.write(f'用时: {format_time(elapsed_time)} ')\n",
    "        if eta > 0:\n",
    "            sys.stdout.write(f'剩余: {format_time(eta)} ')\n",
    "        if step_description:\n",
    "            sys.stdout.write(f'\\n当前任务: {step_description}')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    def finish(self):\n",
    "        \"\"\"完成进度条\"\"\"\n",
    "        total_time = time.time() - self.start_time\n",
    "        sys.stdout.write('\\n')\n",
    "        print(f\"✅ 所有检索任务完成！总用时: {total_time/60:.1f}分钟\")\n",
    "\n",
    "class FrameworkProcessor:\n",
    "    def __init__(self):\n",
    "        self.reference_counter = 1\n",
    "        self.references = {}\n",
    "        \n",
    "    def parse_framework(self, framework_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"解析framework.xml文件\"\"\"\n",
    "        tree = ET.parse(framework_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        framework_data = {\n",
    "            'title': root.find('f-title').text if root.find('f-title') is not None else '',\n",
    "            'background': {\n",
    "                'research_status': root.find('.//f-research-status').text if root.find('.//f-research-status') is not None else '',\n",
    "                'literature_map': root.find('.//f-literature-map').text if root.find('.//f-literature-map') is not None else ''\n",
    "            },\n",
    "            'gaps': [],\n",
    "            'directions': [],\n",
    "            'regional_comparison': {\n",
    "                'domestic': root.find('.//f-domestic').text if root.find('.//f-domestic') is not None else '',\n",
    "                'international': root.find('.//f-international').text if root.find('.//f-international') is not None else ''\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 解析研究空白\n",
    "        gaps = root.find('f-gaps')\n",
    "        if gaps is not None:\n",
    "            for gap in gaps:\n",
    "                if gap.text:\n",
    "                    framework_data['gaps'].append(gap.text.strip())\n",
    "        \n",
    "        # 解析研究方向\n",
    "        directions = root.find('f-directions')\n",
    "        if directions is not None:\n",
    "            for direction in directions.findall('f-direction'):\n",
    "                scope = direction.find('f-scope')\n",
    "                limitations = direction.find('f-inherent-limitations')\n",
    "                framework_data['directions'].append({\n",
    "                    'scope': scope.text.strip() if scope is not None and scope.text else '',\n",
    "                    'limitations': limitations.text.strip() if limitations is not None and limitations.text else ''\n",
    "                })\n",
    "        \n",
    "        return framework_data\n",
    "    \n",
    "    def search_literature(self, query: str, context: str = \"\") -> str:\n",
    "        \"\"\"使用Kimi API进行文献检索\"\"\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"\n",
    "你是一个专业的文献检索助手。请根据用户提供的查询内容，搜索相关的学术文献和研究资料。\n",
    "\n",
    "请按照以下要求进行检索和整理：\n",
    "1. 搜索与查询内容相关的最新学术文献\n",
    "2. 重点关注权威期刊、会议论文和专业报告\n",
    "3. 提供文献的核心观点和主要发现\n",
    "4. 包含作者信息、发表年份、期刊/会议名称等基本信息\n",
    "5. 用中文总结文献内容\n",
    "\n",
    "上下文信息：{context}\n",
    "\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"请搜索关于以下内容的相关文献：{query}\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"builtin_function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"$web_search\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            # 第一次调用：触发联网搜索\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                temperature=0.3,\n",
    "                stream=True\n",
    "            )\n",
    "            \n",
    "            # 处理流式响应\n",
    "            tool_calls = []\n",
    "            for chunk in response:\n",
    "                if chunk.choices[0].delta.tool_calls:\n",
    "                    tool_calls.extend(chunk.choices[0].delta.tool_calls)\n",
    "                \n",
    "                if chunk.choices[0].finish_reason == \"tool_calls\":\n",
    "                    break\n",
    "            \n",
    "            # 处理工具调用\n",
    "            if tool_calls:\n",
    "                tool_call = tool_calls[0]\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"\",\n",
    "                    \"tool_calls\": [tool_call]\n",
    "                })\n",
    "                \n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(tool_call.function.arguments)\n",
    "                })\n",
    "                \n",
    "                # 第二次调用：获取最终结果\n",
    "                final_response = client.chat.completions.create(\n",
    "                    model=MODEL,\n",
    "                    messages=messages,\n",
    "                    temperature=0.3,\n",
    "                    stream=True\n",
    "                )\n",
    "                \n",
    "                full_content = \"\"\n",
    "                for chunk in final_response:\n",
    "                    if chunk.choices[0].delta.content:\n",
    "                        content = chunk.choices[0].delta.content\n",
    "                        print(content, end=\"\", flush=True)  # 实时输出\n",
    "                        full_content += content\n",
    "                \n",
    "                return full_content\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n检索出错: {e}\")\n",
    "            return f\"检索失败：{query}\"\n",
    "        \n",
    "        return \"未能获取到有效响应\"\n",
    "    \n",
    "    def extract_references_from_content(self, content: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"从内容中提取参考文献信息\"\"\"\n",
    "        references = []\n",
    "        \n",
    "        # 简单的参考文献提取逻辑（可以根据实际需要改进）\n",
    "        patterns = [\n",
    "            r'([\\u4e00-\\u9fa5a-zA-Z\\s]+)\\s*\\(\\s*(\\d{4})\\s*\\)\\s*[.。]\\s*([^.。]+)[.。]\\s*([^.。]+)[.。]?',\n",
    "            r'([\\u4e00-\\u9fa5a-zA-Z\\s,]+)[.。]\\s*([^.。]+)[.。]\\s*(\\d{4})[.。]?',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, content)\n",
    "            for match in matches:\n",
    "                if len(match) >= 3:\n",
    "                    ref = {\n",
    "                        'id': str(self.reference_counter),\n",
    "                        'type': 'journal',\n",
    "                        'creators': [match[0].strip()],\n",
    "                        'title': match[2].strip() if len(match) > 2 else '',\n",
    "                        'year': match[1].strip() if len(match) > 1 else '',\n",
    "                        'publication': match[3].strip() if len(match) > 3 else ''\n",
    "                    }\n",
    "                    references.append(ref)\n",
    "                    self.references[str(self.reference_counter)] = ref\n",
    "                    self.reference_counter += 1\n",
    "        \n",
    "        return references\n",
    "    \n",
    "    def calculate_total_steps(self, framework_data: Dict[str, Any]) -> int:\n",
    "        \"\"\"计算总的检索步骤数\"\"\"\n",
    "        total_steps = 0\n",
    "        \n",
    "        # 研究背景：2步（研究现状 + 文献地图）\n",
    "        total_steps += 2\n",
    "        \n",
    "        # 研究空白：每个空白1步\n",
    "        total_steps += len(framework_data['gaps'])\n",
    "        \n",
    "        # 研究方向：每个方向2步（范围 + 局限性）\n",
    "        total_steps += len(framework_data['directions']) * 2\n",
    "        \n",
    "        # 国内外研究：2步（国内 + 国际）\n",
    "        total_steps += 2\n",
    "        \n",
    "        return total_steps\n",
    "    \n",
    "    def generate_material_structure(self, framework_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"生成material结构的XML\"\"\"\n",
    "        # 计算总步骤数并初始化进度条\n",
    "        total_steps = self.calculate_total_steps(framework_data)\n",
    "        progress_bar = ProgressBar(total_steps)\n",
    "        \n",
    "        print(f\"🚀 开始进行文献检索，共 {total_steps} 个检索任务...\\n\")\n",
    "        \n",
    "        # 检索研究现状\n",
    "        progress_bar.update(\"检索研究现状相关文献\")\n",
    "        research_status_content = self.search_literature(\n",
    "            framework_data['background']['research_status'],\n",
    "            \"研究现状和背景\"\n",
    "        )\n",
    "        \n",
    "        # 检索文献地图\n",
    "        progress_bar.update(\"检索文献主题关系相关文献\")\n",
    "        literature_map_content = self.search_literature(\n",
    "            framework_data['background']['literature_map'],\n",
    "            \"文献主题和关系\"\n",
    "        )\n",
    "        \n",
    "        # 检索研究空白\n",
    "        gaps_content = []\n",
    "        for i, gap in enumerate(framework_data['gaps']):\n",
    "            progress_bar.update(f\"检索研究空白 {i+1}/{len(framework_data['gaps'])}: {gap[:50]}...\")\n",
    "            content = self.search_literature(gap, \"研究空白和不足\")\n",
    "            gaps_content.append(content)\n",
    "        \n",
    "        # 检索研究方向\n",
    "        directions_content = []\n",
    "        for i, direction in enumerate(framework_data['directions']):\n",
    "            # 检索方向范围\n",
    "            progress_bar.update(f\"检索研究方向 {i+1} 的范围: {direction['scope'][:50]}...\")\n",
    "            scope_content = self.search_literature(direction['scope'], \"研究方向和范围\")\n",
    "            \n",
    "            # 检索方向局限性\n",
    "            progress_bar.update(f\"检索研究方向 {i+1} 的局限性: {direction['limitations'][:50]}...\")\n",
    "            limitations_content = self.search_literature(direction['limitations'], \"研究局限性\")\n",
    "            \n",
    "            directions_content.append({\n",
    "                'scope': scope_content,\n",
    "                'limitations': limitations_content\n",
    "            })\n",
    "        \n",
    "        # 检索国内外研究\n",
    "        progress_bar.update(\"检索国内研究现状相关文献\")\n",
    "        domestic_content = self.search_literature(\n",
    "            framework_data['regional_comparison']['domestic'],\n",
    "            \"国内研究现状\"\n",
    "        )\n",
    "        \n",
    "        progress_bar.update(\"检索国际研究现状相关文献\")\n",
    "        international_content = self.search_literature(\n",
    "            framework_data['regional_comparison']['international'],\n",
    "            \"国际研究现状\"\n",
    "        )\n",
    "        \n",
    "        # 完成进度条\n",
    "        progress_bar.finish()\n",
    "        \n",
    "        print(\"\\n📚 开始提取参考文献信息...\")\n",
    "        \n",
    "        # 提取所有参考文献\n",
    "        all_content = [research_status_content, literature_map_content] + gaps_content\n",
    "        for direction in directions_content:\n",
    "            all_content.extend([direction['scope'], direction['limitations']])\n",
    "        all_content.extend([domestic_content, international_content])\n",
    "        \n",
    "        for content in all_content:\n",
    "            self.extract_references_from_content(content)\n",
    "        \n",
    "        print(f\"✅ 已提取 {len(self.references)} 条参考文献\")\n",
    "        print(\"\\n🔧 正在生成XML结构...\")\n",
    "        \n",
    "        # 生成XML结构\n",
    "        xml_content = f\"\"\"\n",
    "<material>\n",
    "  <t-chapters>\n",
    "    \n",
    "    <!-- 3. 研究背景 -->\n",
    "    <t-chapter id=\"c3\">\n",
    "      <t-heading>研究背景</t-heading>\n",
    "      \n",
    "      <!-- 3.1 研究现状 -->\n",
    "      <t-section id=\"c3-s1\">\n",
    "        <t-heading>研究现状</t-heading>\n",
    "        <t-purpose>本节将系统梳理{framework_data['title']}领域的已有研究成果</t-purpose>\n",
    "        \n",
    "        <t-point id=\"c3-s1-p1\">\n",
    "          <t-claim>{research_status_content[:200]}...</t-claim>\n",
    "          <t-keywords>研究现状, 发展历程, 主要成果</t-keywords>\n",
    "          <t-gap>需要进一步补充最新研究进展</t-gap>\n",
    "        </t-point>\n",
    "        \n",
    "        <t-point id=\"c3-s1-p2\">\n",
    "          <t-claim>{literature_map_content[:200]}...</t-claim>\n",
    "          <t-keywords>文献主题, 研究关系, 知识图谱</t-keywords>\n",
    "          <t-gap>需要深入分析主题间的内在联系</t-gap>\n",
    "        </t-point>\n",
    "        \n",
    "      </t-section>\n",
    "    </t-chapter>\n",
    "    \n",
    "    <!-- 4. 当前研究中存在的问题和不足 -->\n",
    "    <t-chapter id=\"c4\">\n",
    "      <t-heading>当前研究中存在的问题和不足</t-heading>\n",
    "      \n",
    "      <t-section id=\"c4-s1\">\n",
    "        <t-heading>主要研究空白</t-heading>\n",
    "\"\"\"\n",
    "        \n",
    "        # 添加研究空白内容\n",
    "        for i, gap_content in enumerate(gaps_content):\n",
    "            xml_content += f\"\"\"\n",
    "        <t-point id=\"c4-s1-p{i+1}\">\n",
    "          <t-claim>{gap_content[:200]}...</t-claim>\n",
    "          <t-gap>待进一步深入研究</t-gap>\n",
    "        </t-point>\n",
    "\"\"\"\n",
    "        \n",
    "        xml_content += \"\"\"\n",
    "      </t-section>\n",
    "    </t-chapter>\n",
    "    \n",
    "    <!-- 5. 当前研究的主要方向及其不足 -->\n",
    "    <t-chapter id=\"c5\">\n",
    "      <t-heading>当前研究的主要方向及其不足</t-heading>\n",
    "\"\"\"\n",
    "        \n",
    "        # 添加研究方向内容\n",
    "        for i, direction_content in enumerate(directions_content):\n",
    "            xml_content += f\"\"\"\n",
    "      <t-section id=\"c5-s{i+1}\">\n",
    "        <t-heading>方向{i+1}</t-heading>\n",
    "        <t-point id=\"c5-s{i+1}-p1\">\n",
    "          <t-claim>{direction_content['scope'][:200]}...</t-claim>\n",
    "          <t-gap>{direction_content['limitations'][:200]}...</t-gap>\n",
    "        </t-point>\n",
    "      </t-section>\n",
    "\"\"\"\n",
    "        \n",
    "        xml_content += f\"\"\"\n",
    "    </t-chapter>\n",
    "    \n",
    "    <!-- 6. 国内外相关研究比较 -->\n",
    "    <t-chapter id=\"c6\">\n",
    "      <t-heading>国内外相关研究比较</t-heading>\n",
    "      \n",
    "      <t-section id=\"c6-s1\">\n",
    "        <t-heading>国内研究</t-heading>\n",
    "        <t-point id=\"c6-s1-p1\">\n",
    "          <t-claim>{domestic_content[:200]}...</t-claim>\n",
    "        </t-point>\n",
    "      </t-section>\n",
    "      \n",
    "      <t-section id=\"c6-s2\">\n",
    "        <t-heading>国外研究</t-heading>\n",
    "        <t-point id=\"c6-s2-p1\">\n",
    "          <t-claim>{international_content[:200]}...</t-claim>\n",
    "        </t-point>\n",
    "      </t-section>\n",
    "      \n",
    "      <t-section id=\"c6-s3\">\n",
    "        <t-heading>差异与启示</t-heading>\n",
    "        <t-point id=\"c6-s3-p1\">\n",
    "          <t-claim>通过比较分析，可以发现国内外研究的差异和互补性</t-claim>\n",
    "        </t-point>\n",
    "      </t-section>\n",
    "    </t-chapter>\n",
    "    \n",
    "  </t-chapters>\n",
    "  \n",
    "  <!-- 参考文献容器 -->\n",
    "  <t-sources>\n",
    "\"\"\"\n",
    "        \n",
    "        # 添加参考文献\n",
    "        for ref_id, ref_data in self.references.items():\n",
    "            creators_xml = '\\n'.join([f'    <t-creator>{creator}</t-creator>' for creator in ref_data['creators']])\n",
    "            xml_content += f\"\"\"\n",
    "    <t-ref id=\"{ref_id}\" type=\"{ref_data['type']}\">\n",
    "{creators_xml}\n",
    "      <t-title>{ref_data['title']}</t-title>\n",
    "      <t-publication>\n",
    "        <t-publisher>{ref_data['publication']}</t-publisher>\n",
    "        <t-year>{ref_data['year']}</t-year>\n",
    "      </t-publication>\n",
    "    </t-ref>\n",
    "\"\"\"\n",
    "        \n",
    "        xml_content += \"\"\"\n",
    "  </t-sources>\n",
    "</material>\n",
    "\"\"\"\n",
    "        \n",
    "        return xml_content\n",
    "    \n",
    "    def process_framework(self, framework_path: str, output_path: str = None):\n",
    "        \"\"\"处理整个框架，生成material结构\"\"\"\n",
    "        print(f\"📖 开始处理框架文件: {framework_path}\")\n",
    "        \n",
    "        # 解析框架\n",
    "        framework_data = self.parse_framework(framework_path)\n",
    "        print(f\"✅ 框架解析完成，标题: {framework_data['title']}\")\n",
    "        \n",
    "        # 生成material结构\n",
    "        material_xml = self.generate_material_structure(framework_data)\n",
    "        \n",
    "        # 保存结果\n",
    "        if output_path is None:\n",
    "            output_path = \"material.xml\"\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(material_xml)\n",
    "        \n",
    "        print(f\"\\n🎉 处理完成，结果已保存到: {output_path}\")\n",
    "        return material_xml\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    processor = FrameworkProcessor()\n",
    "    \n",
    "    # 处理framework.xml文件\n",
    "    framework_path = \"framework.xml\"\n",
    "    output_path = \"material-2.xml\"\n",
    "    \n",
    "    try:\n",
    "        result = processor.process_framework(framework_path, output_path)\n",
    "        print(\"\\n=== 🎊 所有任务完成 ===\")\n",
    "        print(f\"📄 生成的material结构已保存到: {output_path}\")\n",
    "        print(f\"📚 共提取了 {len(processor.references)} 条参考文献\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 处理过程中出现错误: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
