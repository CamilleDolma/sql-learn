{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86efa528",
   "metadata": {},
   "source": [
    "## å‚è€ƒæ–‡çŒ® XML â†’ å‚è€ƒæ–‡çŒ®æ–‡æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a3b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] ææ™“ä¸œ, å¼ åº†çº¢, å¶ç‘¾ç³. æ°”å€™å­¦ç ”ç©¶çš„è‹¥å¹²ç†è®ºé—®é¢˜[J]. åŒ—äº¬å¤§å­¦å­¦æŠ¥(è‡ªç„¶ç§‘å­¦ç‰ˆ), 1999,35(1): 101-106.\n",
      "[2] ä½™æ•. å‡ºç‰ˆé›†å›¢ç ”ç©¶[M]. åŒ—äº¬, ä¸­å›½ä¹¦ç±å‡ºç‰ˆç¤¾, 2001: 179-193.\n",
      "[3] è§é’°. å‡ºç‰ˆä¸šä¿¡æ¯åŒ–è¿ˆå…¥å¿«è½¦é“[EB/OL]. 2001[2023-03-06]. http://www.creader.com/news/20011219/200112190019.html.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "TYPE_LABEL = {\n",
    "    \"journal\": \"J\", \"book\": \"M\", \"conference\": \"C\",\n",
    "    \"web\": \"EB/OL\", \"patent\": \"P\", \"thesis\": \"D\",\n",
    "    \"report\": \"R\", \"standard\": \"S\", \"newspaper\": \"N\"\n",
    "}\n",
    "\n",
    "def pick_text(parent, tag, default=\"\"):\n",
    "    e = parent.find(tag)\n",
    "    return (e.text or \"\").strip() if e is not None else default\n",
    "\n",
    "def format_creators(creators):\n",
    "    names = [c.text.strip() for c in creators if c.text]\n",
    "    if len(names) > 3:\n",
    "        return \", \".join(names[:3]) + \", ç­‰\"\n",
    "    return \", \".join(names)\n",
    "\n",
    "def build_journal_line(ref):\n",
    "    creators = ref.findall(\"r-creator\")\n",
    "    title = pick_text(ref, \"r-title\")\n",
    "    subtitle = pick_text(ref, \"r-subtitle\")\n",
    "    if subtitle:\n",
    "        title += f\": {subtitle}\"\n",
    "\n",
    "    pub = ref.find(\"r-publication\")\n",
    "    journal = pick_text(pub, \"r-publisher\")\n",
    "    year = pick_text(pub, \"r-year\")\n",
    "    vol = pick_text(pub, \"r-volume\")\n",
    "    iss = pick_text(pub, \"r-issue\")\n",
    "    pages = pick_text(ref, \"r-pages\")\n",
    "\n",
    "    line = f\"{format_creators(creators)}. {title}[J]. {journal}\"\n",
    "    if year or vol or iss:\n",
    "        line += f\", {year}\"\n",
    "        if vol:\n",
    "            line += f\",{vol}\"\n",
    "        if iss:\n",
    "            line += f\"({iss})\"\n",
    "    if pages:\n",
    "        line += f\": {pages}\"\n",
    "    return line + \".\"\n",
    "\n",
    "def build_book_line(ref):\n",
    "    creators = ref.findall(\"r-creator\")\n",
    "    title = pick_text(ref, \"r-title\")\n",
    "    subtitle = pick_text(ref, \"r-subtitle\")\n",
    "    if subtitle:\n",
    "        title += f\": {subtitle}\"\n",
    "\n",
    "    edition = pick_text(ref, \"r-edition\")\n",
    "    pub = ref.find(\"r-publication\")\n",
    "    place = pick_text(pub, \"r-place\")\n",
    "    publisher = pick_text(pub, \"r-publisher\")\n",
    "    year = pick_text(pub, \"r-year\")\n",
    "    pages = pick_text(ref, \"r-pages\")\n",
    "\n",
    "    line = f\"{format_creators(creators)}. {title}[M]\"\n",
    "    if edition:\n",
    "        line += f\". {edition}\"\n",
    "    pub_part = \", \".join(filter(None, [place, publisher]))\n",
    "    if pub_part:\n",
    "        line += f\". {pub_part}\"\n",
    "    if year:\n",
    "        line += f\", {year}\"\n",
    "    if pages:\n",
    "        line += f\": {pages}\"\n",
    "    return line + \".\"\n",
    "\n",
    "def build_web_line(ref):\n",
    "    creators = ref.findall(\"r-creator\")\n",
    "    title = pick_text(ref, \"r-title\")\n",
    "    year = pick_text(ref.find(\"r-publication\"), \"r-year\")\n",
    "    url = pick_text(ref, \"r-url\")\n",
    "    accessed = pick_text(ref, \"r-accessed\")\n",
    "\n",
    "    line = f\"{format_creators(creators)}. {title}[EB/OL]\"\n",
    "    if year:\n",
    "        line += f\". {year}\"\n",
    "    if accessed:\n",
    "        line += f\"[{accessed}]\"\n",
    "    if url:\n",
    "        line += f\". {url}\"\n",
    "    return line + \".\"\n",
    "\n",
    "def format_ref(ref):\n",
    "    t = ref.get(\"type\", \"\")\n",
    "    if t == \"journal\":\n",
    "        return build_journal_line(ref)\n",
    "    if t in {\"book\", \"thesis\", \"report\", \"standard\"}:\n",
    "        return build_book_line(ref)\n",
    "    if t in {\"web\", \"newspaper\"}:\n",
    "        return build_web_line(ref)\n",
    "    # å…¶ä»–ç±»å‹å¯æŒ‰éœ€æ‰©å±•\n",
    "    return f\"<!-- type {t} not implemented -->\"\n",
    "\n",
    "def xml2gbt(xml_str: str) -> List[str]:\n",
    "    root = ET.fromstring(xml_str)\n",
    "    refs = root.findall(\"r-ref\")\n",
    "    return [f\"[{idx}] {format_ref(r)}\" for idx, r in enumerate(refs, 1)]\n",
    "\n",
    "# ---------- 5. å‘½ä»¤è¡Œ ----------\n",
    "if __name__ == \"__main__\":\n",
    "    demo_xml = \"\"\"\n",
    "    <r-refs>\n",
    "      <r-ref id=\"1\" type=\"journal\">\n",
    "        <r-creator>ææ™“ä¸œ</r-creator>\n",
    "        <r-creator>å¼ åº†çº¢</r-creator>\n",
    "        <r-creator>å¶ç‘¾ç³</r-creator>\n",
    "        <r-title>æ°”å€™å­¦ç ”ç©¶çš„è‹¥å¹²ç†è®ºé—®é¢˜</r-title>\n",
    "        <r-publication>\n",
    "          <r-publisher>åŒ—äº¬å¤§å­¦å­¦æŠ¥(è‡ªç„¶ç§‘å­¦ç‰ˆ)</r-publisher>\n",
    "          <r-year>1999</r-year>\n",
    "          <r-volume>35</r-volume>\n",
    "          <r-issue>1</r-issue>\n",
    "        </r-publication>\n",
    "        <r-pages>101-106</r-pages>\n",
    "      </r-ref>\n",
    "\n",
    "      <r-ref id=\"2\" type=\"book\">\n",
    "        <r-creator>ä½™æ•</r-creator>\n",
    "        <r-title>å‡ºç‰ˆé›†å›¢ç ”ç©¶</r-title>\n",
    "        <r-publication>\n",
    "          <r-place>åŒ—äº¬</r-place>\n",
    "          <r-publisher>ä¸­å›½ä¹¦ç±å‡ºç‰ˆç¤¾</r-publisher>\n",
    "          <r-year>2001</r-year>\n",
    "        </r-publication>\n",
    "        <r-pages>179-193</r-pages>\n",
    "      </r-ref>\n",
    "\n",
    "      <r-ref id=\"3\" type=\"web\">\n",
    "        <r-creator>è§é’°</r-creator>\n",
    "        <r-title>å‡ºç‰ˆä¸šä¿¡æ¯åŒ–è¿ˆå…¥å¿«è½¦é“</r-title>\n",
    "        <r-publication>\n",
    "          <r-year>2001</r-year>\n",
    "        </r-publication>\n",
    "        <r-url>http://www.creader.com/news/20011219/200112190019.html</r-url>\n",
    "        <r-accessed>2023-03-06</r-accessed>\n",
    "      </r-ref>\n",
    "    </r-refs>\n",
    "    \"\"\"\n",
    "    for line in xml2gbt(demo_xml):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4450578",
   "metadata": {},
   "source": [
    "## ç”Ÿæˆæ¡†æ¶ï¼ˆä½¿ç”¨é•¿æ€è€ƒï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf0adff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤” Thinking...\n",
      "\n",
      "æˆ‘ need to create a structured outline for a literature review on the topic \"LSTM çš„æ‹“å±•åº”ç”¨\" in Simplified Chinese. The outline should cover research background, gaps in current research, main research directions, and regional comparisons. I'll use the provided XML structure to format my response.\n",
      "\n",
      "First, I'll think through each section:\n",
      "\n",
      "1. Title: I need to create a targeted title that reflects the focus on LSTM's extended applications. Something like \"LSTM æ‹“å±•åº”ç”¨çš„å‰æ²¿ç ”ç©¶ä¸å®è·µæ¢ç´¢\" (Frontier Research and Practical Exploration of LSTM Extended Applications) could work.\n",
      "\n",
      "2. Research Background:\n",
      "   - Research Status: I'll provide a brief overview of LSTM's current applications, mentioning its use in time series prediction, natural language processing, speech recognition, etc.\n",
      "   - Literature Map: I'll describe the main themes like LSTM variants, application domains, and integration with other technologies.\n",
      "\n",
      "3. Research Gaps:\n",
      "   - I'll identify major gaps such as LSTM's limitations in handling long-term dependencies, computational efficiency issues, and lack of interpretability in complex models.\n",
      "\n",
      "4. Main Directions:\n",
      "   - I'll outline primary research directions including model optimization, interdisciplinary applications, and hybrid model development. For each direction, I'll mention inherent limitations.\n",
      "\n",
      "5. Regional Comparison:\n",
      "   - I'll summarize domestic (Chinese) research focusing on practical applications and international research emphasizing theoretical innovations and interdisciplinary approaches.\n",
      "\n",
      "Now, I'll structure this into the required XML format with placeholder content for each section. I'll make sure the content is concise but informative enough to guide further research and writing.<framework>\n",
      "<f-title>LSTM æ‹“å±•åº”ç”¨çš„å‰æ²¿ç ”ç©¶ä¸å®è·µæ¢ç´¢</f-title>\n",
      "<f-background>\n",
      "  <f-research-status>å½“å‰ LSTM ç ”ç©¶å·²å¹¿æ³›è¦†ç›–æ—¶é—´åºåˆ—é¢„æµ‹ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰å¤šä¸ªé¢†åŸŸï¼Œå½¢æˆäº†åŒ…æ‹¬åŒå‘ LSTMã€æ·±åº¦ LSTMã€æ³¨æ„åŠ›æœºåˆ¶èåˆ LSTM ç­‰å¤šç§å˜ä½“ã€‚åœ¨æ™ºèƒ½äº¤é€šæµé‡é¢„æµ‹ã€é‡‘èæ•°æ®åˆ†æã€åŒ»ç–—å¥åº·ç›‘æµ‹ç­‰æ–¹é¢æœ‰å¤§é‡åº”ç”¨æ¡ˆä¾‹ï¼Œä½†å¤§éƒ¨åˆ†ç ”ç©¶ä»é›†ä¸­åœ¨æ¨¡å‹æ€§èƒ½ä¼˜åŒ–è€Œéè·¨é¢†åŸŸèåˆåº”ç”¨ã€‚</f-research-status>\n",
      "  <f-literature-map>ä¸»è¦ç ”ç©¶ä¸»é¢˜åŒ…æ‹¬ LSTM æ¶æ„æ”¹è¿›ï¼ˆå¦‚é—¨æ§æœºåˆ¶ä¼˜åŒ–ï¼‰ã€ä¸å…¶ä»–ç®—æ³•èåˆï¼ˆå¦‚ CNNã€Transformerï¼‰ã€ç‰¹å®šé¢†åŸŸåº”ç”¨å¼€å‘ï¼ˆå¦‚è¯­éŸ³è¯†åˆ«ã€æ–‡æœ¬ç”Ÿæˆï¼‰ã€‚å„ä¸»é¢˜é—´å…³ç³»å‘ˆç°ä»åŸºç¡€ç†è®ºç ”ç©¶åˆ°è¡Œä¸šåº”ç”¨æ‹“å±•çš„å±‚çº§ç»“æ„ï¼Œè¿‘å¹´å‡ºç°å¤šæ¨¡æ€æ•°æ®å¤„ç†ä¸ LSTM ç»“åˆçš„æ–°è¶‹åŠ¿ã€‚</f-literature-map>\n",
      "</f-background>\n",
      "<f-gaps>\n",
      "  <f-gap-1>ç°æœ‰ç ”ç©¶åœ¨å¤„ç†è¶…é•¿åºåˆ—æ•°æ®æ—¶ï¼ŒLSTM ä»å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå°šæœªå½¢æˆæœ‰æ•ˆçš„é€šç”¨è§£å†³æ–¹æ¡ˆï¼Œå¤šæ•°ä¼˜åŒ–æ–¹æ³•ä»…é’ˆå¯¹ç‰¹å®šåœºæ™¯æœ‰æ•ˆã€‚</f-gap-1>\n",
      "  <f-gap-2>è·¨é¢†åŸŸçŸ¥è¯†è¿ç§»åº”ç”¨ä¸è¶³ï¼Œä¸åŒè¡Œä¸š LSTM æ¨¡å‹å¤§å¤šç‹¬ç«‹å¼€å‘ï¼Œç¼ºä¹å¯å¤ç”¨çš„çŸ¥è¯†ä½“ç³»å’Œè¿ç§»å­¦ä¹ æ¡†æ¶ï¼Œå¯¼è‡´ç ”å‘æˆæœ¬é‡å¤ã€‚</f-gap-2>\n",
      "  <f-gap-3>æ¨¡å‹å¯è§£é‡Šæ€§ç ”ç©¶è–„å¼±ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚åº”ç”¨åœºæ™¯ä¸­ï¼Œéš¾ä»¥å‘éæŠ€æœ¯ç”¨æˆ·æ¸…æ™°è§£é‡Š LSTM å†³ç­–é€»è¾‘ï¼Œé™åˆ¶äº†å…¶åœ¨å…³é”®å†³ç­–é¢†åŸŸçš„åº”ç”¨æ¨å¹¿ã€‚</f-gap-3>\n",
      "</f-gaps>\n",
      "<f-directions>\n",
      "  <f-direction>\n",
      "    <f-scope>æ¨¡å‹æ¶æ„åˆ›æ–°ä¸æ€§èƒ½ä¼˜åŒ–ï¼ŒåŒ…æ‹¬æ–°å‹é—¨æ§æœºåˆ¶è®¾è®¡ã€è®¡ç®—æ•ˆç‡æå‡ã€å†…å­˜å ç”¨ä¼˜åŒ–ç­‰æ–¹å‘ï¼Œé‡ç‚¹å…³æ³¨åœ¨ç§»åŠ¨ç»ˆç«¯å’Œè¾¹ç¼˜è®¡ç®—è®¾å¤‡ä¸Šçš„è½»é‡åŒ–éƒ¨ç½²ã€‚</f-scope>\n",
      "    <f-inherent-limitations>è¯¥æ–¹å‘å¯èƒ½é¢ä¸´ç†è®ºç“¶é¢ˆï¼Œç°æœ‰è®¡ç®—æ¡†æ¶å¯¹åŸºç¡€æ¶æ„æ”¹åŠ¨æ”¯æŒæœ‰é™ï¼Œä¸”æ€§èƒ½æå‡ä¸æ¨¡å‹å¤æ‚åº¦å¢åŠ å­˜åœ¨çŸ›ç›¾å…³ç³»ã€‚</f-inherent-limitations>\n",
      "  </f-direction>\n",
      "  <f-direction>\n",
      "    <f-scope>è·¨é¢†åŸŸèåˆåº”ç”¨å¼€å‘ï¼Œæ¢ç´¢ LSTM åœ¨æ™ºæ…§åŸå¸‚ã€å·¥ä¸šç‰©è”ç½‘ã€ç”Ÿç‰©ä¿¡æ¯å­¦ç­‰æ–°å…´é¢†åŸŸçš„åˆ›æ–°åº”ç”¨ï¼Œæ³¨é‡å¤šæºå¼‚æ„æ•°æ®å¤„ç†èƒ½åŠ›ã€‚</f-scope>\n",
      "    <f-inherent-limitations>è·¨é¢†åŸŸåº”ç”¨é¢ä¸´æ•°æ®æ ‡å‡†ä¸ç»Ÿä¸€ã€é¢†åŸŸçŸ¥è¯†å·®å¼‚å¤§ç­‰æŒ‘æˆ˜ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸é¢†åŸŸé€‚é…ç²¾åº¦å­˜åœ¨å¹³è¡¡éš¾é¢˜ã€‚</f-inherent-limitations>\n",
      "  </f-direction>\n",
      "  <f-direction>\n",
      "    <f-scope>å¯è§£é‡Šæ€§äººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰ä¸ LSTM ç»“åˆç ”ç©¶ï¼Œå¼€å‘é¢å‘ä¸åŒç”¨æˆ·ç¾¤ä½“çš„å¯è§†åŒ–è§£é‡Šå·¥å…·ï¼Œå»ºç«‹æ¨¡å‹å†³ç­–è¿‡ç¨‹çš„é€æ˜åº¦è¯„ä¼°ä½“ç³»ã€‚</f-scope>\n",
      "    <f-inherent-limitations>å¯è§£é‡Šæ€§å¢å¼ºå¯èƒ½ä»¥ç‰ºç‰²éƒ¨åˆ†æ¨¡å‹æ€§èƒ½ä¸ºä»£ä»·ï¼Œä¸”ä¸åŒè§£é‡Šæ–¹æ³•åœ¨æŠ€æœ¯å…¼å®¹æ€§å’Œç”¨æˆ·ä½“éªŒä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚</f-inherent-limitations>\n",
      "  </f-direction>\n",
      "</f-directions>\n",
      "<f-regional-comparison>\n",
      "  <f-domestic>å›½å†…ç ”ç©¶ä¾§é‡äºåº”ç”¨å¼€å‘å’Œå·¥ç¨‹å®ç°ï¼Œåœ¨æ™ºèƒ½å®‰é˜²è§†é¢‘åˆ†æã€ç§»åŠ¨æ”¯ä»˜é£é™©é¢„æµ‹ã€æ™ºèƒ½å®¢æœç³»ç»Ÿç­‰é¢†åŸŸæœ‰å¤§é‡è½åœ°æ¡ˆä¾‹ï¼Œç ”ç©¶å›¢é˜Ÿä»¥ä¼ä¸šç ”å‘éƒ¨é—¨å’Œåº”ç”¨å‹é«˜æ ¡ä¸ºä¸»ï¼Œå‘è¡¨è®ºæ–‡å¤šé›†ä¸­äºå›½å†…æœŸåˆŠå’Œåº”ç”¨ç±»ä¼šè®®ã€‚</f-domestic>\n",
      "  <f-international>å›½é™…ç ”ç©¶æ›´æ³¨é‡åŸºç¡€ç†è®ºåˆ›æ–°å’Œè·¨å­¦ç§‘åˆä½œï¼Œæ¬§ç¾é«˜æ ¡å’Œç ”ç©¶æœºæ„åœ¨ LSTM ä¸ç¥ç»ç§‘å­¦ã€è®¤çŸ¥å¿ƒç†å­¦äº¤å‰ç ”ç©¶æ–¹é¢æˆæœçªå‡ºï¼Œäºšæ´²åœ°åŒºï¼ˆå°¤å…¶æ˜¯æ—¥æœ¬å’ŒéŸ©å›½ï¼‰åœ¨æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸçš„ LSTM åº”ç”¨ç ”ç©¶å¤„äºé¢†å…ˆåœ°ä½ï¼Œè®ºæ–‡å‘è¡¨å¤šè§äºé¡¶çº§å­¦æœ¯ä¼šè®®å’Œå›½é™…æƒå¨æœŸåˆŠã€‚</f-international>\n",
      "</f-regional-comparison>\n",
      "</framework>"
     ]
    }
   ],
   "source": [
    "\n",
    "import openai, os, sys\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1. é…ç½®\n",
    "MODEL = \"kimi-thinking-preview\"\n",
    "API_KEY = \"sk-ngwOcq4h7reY7qL7jQeOVkmZhWCg9Xh95ilq2NkXIsArpQRC\"\n",
    "BASE_URL = \"https://api.moonshot.cn/v1\"\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "\n",
    "# 2. ç”Ÿæˆï¼ˆå®Œå…¨æµå¼ï¼‰\n",
    "def gen_outline_stream(topic: str):\n",
    "    prompt = f\"\"\"\n",
    "You are tasked with creating a structured outline for a literature review on a given topic in Simplified Chinese. This outline will serve as a framework for further research and writing. Your goal is to generate a comprehensive structure that covers the research background, gaps in current research, main research directions, and regional comparisons. ä½¿ç”¨ç®€ä½“ä¸­æ–‡è¿›è¡Œæ€è€ƒã€‚\n",
    "\n",
    "The topic for the literature review is given by user:\n",
    "<topic>\n",
    "{topic}\n",
    "</topic>\n",
    "\n",
    "Title should be determined according to needs and should be targeted to a certain extent, such as cutting-edge issues in disciplinary development, new achievements and new technologies in scientific research, hot social and economic issues, and practical problems in production practice.\n",
    "\n",
    "Before generating the final output, use a scratchpad to think through the structure and content for each section. Consider the following:\n",
    "- What is the current state of research on this topic?\n",
    "- What are the main gaps or limitations in existing research?\n",
    "- What are the primary research directions within this field?\n",
    "- How does research in this area differ between domestic and international contexts?\n",
    "\n",
    "Once you have thought through these elements, generate the outline using the following XML structure. Provide brief, placeholder content for each section to guide further research and writing:\n",
    "\n",
    "<framework>\n",
    "<f-title>{{Title}}</f-title>\n",
    "<!-- 3. Research Background (Abstract Framework) -->\n",
    "<f-background>\n",
    "  <f-research-status>\n",
    "    <!-- Provide a brief overview of the current research status -->\n",
    "  </f-research-status>\n",
    "  <f-literature-map>\n",
    "    <!-- Describe the main themes and relationships within the topic -->\n",
    "  </f-literature-map>\n",
    "</f-background>\n",
    "\n",
    "<!-- 4. Research Gaps (Abstract Framework) -->\n",
    "<f-gaps>\n",
    "  <f-gap-1>\n",
    "    <!-- Describe the first major gap in current research -->\n",
    "  </f-gap-1>\n",
    "  <f-gap-2>\n",
    "    <!-- Describe the second major gap in current research -->\n",
    "  </f-gap-2>\n",
    "  <!-- Add more gap elements if necessary -->\n",
    "</f-gaps>\n",
    "\n",
    "<!-- 5. Main Directions (Abstract Framework) -->\n",
    "<f-directions>\n",
    "  <f-direction>\n",
    "    <f-scope>\n",
    "      <!-- Name and describe the scope of the first main research direction -->\n",
    "    </f-scope>\n",
    "    <f-inherent-limitations>\n",
    "      <!-- Outline the inherent limitations of this research direction -->\n",
    "    </f-inherent-limitations>\n",
    "  </f-direction>\n",
    "  <!-- Add more direction elements if necessary -->\n",
    "</f-directions>\n",
    "\n",
    "<!-- 6. Regional Comparison (Abstract Framework) -->\n",
    "<f-regional-comparison>\n",
    "  <f-domestic>\n",
    "    <!-- Summarize the state of domestic research on the topic -->\n",
    "  </f-domestic>\n",
    "  <f-international>\n",
    "    <!-- Summarize the state of international research on the topic -->\n",
    "  </f-international>\n",
    "</f-regional-comparison>\n",
    "\n",
    "Ensure that each section contains relevant placeholder content that can guide further research and writing. The content should be concise yet informative, providing a clear direction for the literature review\n",
    "                        \n",
    "NOTE!!! It is strictly forbidden to output any other text outside the given XML framework!!!\n",
    "\"\"\"\n",
    "    print(\"ğŸ¤” Thinking...\\n\")\n",
    "    buffer = []                              # ç”¨äºæ”¶é›†å®Œæ•´æ­£æ–‡\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=2048,\n",
    "        temperature=0.8,\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if hasattr(delta, \"reasoning_content\") and delta.reasoning_content:\n",
    "            # å¦‚éœ€æŸ¥çœ‹æ¨ç†è¿‡ç¨‹å¯å–æ¶ˆä¸‹è¡Œæ³¨é‡Š\n",
    "            print(delta.reasoning_content, end=\"\", flush=True)\n",
    "        if delta.content:\n",
    "            print(delta.content, end=\"\", flush=True)\n",
    "            buffer.append(delta.content)\n",
    "    full_text = \"\".join(buffer)\n",
    "    return full_text\n",
    "\n",
    "# 3. è¿è¡Œ\n",
    "if __name__ == \"__main__\":\n",
    "    topic = \"LSTM çš„æ‹“å±•åº”ç”¨\"\n",
    "    framework = gen_outline_stream(topic)\n",
    "    with open(\"framework.xml\", 'w', encoding='utf-8') as f:\n",
    "        f.write(framework)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e83126",
   "metadata": {},
   "source": [
    "## ç”Ÿæˆå®Œæ•´ææ–™ï¼ˆä½¿ç”¨æ£€ç´¢ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹å¤„ç†æ¡†æ¶æ–‡ä»¶: framework.xml\n",
      "æ¡†æ¶è§£æå®Œæˆï¼Œæ ‡é¢˜: LSTM æ‹“å±•åº”ç”¨çš„å‰æ²¿ç ”ç©¶ä¸å®è·µæ¢ç´¢\n",
      "å¼€å§‹è¿›è¡Œæ–‡çŒ®æ£€ç´¢...\n",
      "æ£€ç´¢ç ”ç©¶ç°çŠ¶...\n",
      "æ£€ç´¢æ–‡çŒ®ä¸»é¢˜å…³ç³»...\n",
      "æ£€ç´¢ç ”ç©¶ç©ºç™½ 1...\n",
      "æ£€ç´¢ç ”ç©¶ç©ºç™½ 2...\n",
      "æ£€ç´¢ç ”ç©¶ç©ºç™½ 3...\n",
      "æ£€ç´¢ç ”ç©¶æ–¹å‘ 1...\n",
      "æ£€ç´¢ç ”ç©¶æ–¹å‘ 2...\n",
      "æ£€ç´¢ç ”ç©¶æ–¹å‘ 3...\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from typing import Dict, List, Any\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# è®¾ç½®å®¢æˆ·ç«¯\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-ngwOcq4h7reY7qL7jQeOVkmZhWCg9Xh95ilq2NkXIsArpQRC\",\n",
    "    base_url=\"https://api.moonshot.cn/v1\"\n",
    ")\n",
    "\n",
    "MODEL = \"kimi-k2-0711-preview\"\n",
    "\n",
    "class ProgressBar:\n",
    "    def __init__(self, total_steps: int, width: int = 50):\n",
    "        self.total_steps = total_steps\n",
    "        self.current_step = 0\n",
    "        self.width = width\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def update(self, step_description: str = \"\"):\n",
    "        \"\"\"æ›´æ–°è¿›åº¦æ¡\"\"\"\n",
    "        self.current_step += 1\n",
    "        progress = self.current_step / self.total_steps\n",
    "        filled_width = int(self.width * progress)\n",
    "        \n",
    "        # è®¡ç®—å·²ç”¨æ—¶é—´å’Œé¢„ä¼°å‰©ä½™æ—¶é—´\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        if self.current_step > 0:\n",
    "            avg_time_per_step = elapsed_time / self.current_step\n",
    "            remaining_steps = self.total_steps - self.current_step\n",
    "            eta = avg_time_per_step * remaining_steps\n",
    "        else:\n",
    "            eta = 0\n",
    "            \n",
    "        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º\n",
    "        def format_time(seconds):\n",
    "            if seconds < 60:\n",
    "                return f\"{seconds:.0f}s\"\n",
    "            elif seconds < 3600:\n",
    "                return f\"{seconds//60:.0f}m{seconds%60:.0f}s\"\n",
    "            else:\n",
    "                return f\"{seconds//3600:.0f}h{(seconds%3600)//60:.0f}m\"\n",
    "        \n",
    "        # æ„å»ºè¿›åº¦æ¡\n",
    "        bar = 'â–ˆ' * filled_width + 'â–‘' * (self.width - filled_width)\n",
    "        percentage = progress * 100\n",
    "        \n",
    "        # æ¸…é™¤å½“å‰è¡Œå¹¶æ‰“å°æ–°çš„è¿›åº¦æ¡\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(f'è¿›åº¦: [{bar}] {percentage:.1f}% ({self.current_step}/{self.total_steps}) ')\n",
    "        sys.stdout.write(f'ç”¨æ—¶: {format_time(elapsed_time)} ')\n",
    "        if eta > 0:\n",
    "            sys.stdout.write(f'å‰©ä½™: {format_time(eta)} ')\n",
    "        if step_description:\n",
    "            sys.stdout.write(f'\\nå½“å‰ä»»åŠ¡: {step_description}')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    def finish(self):\n",
    "        \"\"\"å®Œæˆè¿›åº¦æ¡\"\"\"\n",
    "        total_time = time.time() - self.start_time\n",
    "        sys.stdout.write('\\n')\n",
    "        print(f\"âœ… æ‰€æœ‰æ£€ç´¢ä»»åŠ¡å®Œæˆï¼æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ\")\n",
    "\n",
    "class FrameworkProcessor:\n",
    "    def __init__(self):\n",
    "        self.reference_counter = 1\n",
    "        self.references = {}\n",
    "        \n",
    "    def parse_framework(self, framework_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"è§£æframework.xmlæ–‡ä»¶\"\"\"\n",
    "        tree = ET.parse(framework_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        framework_data = {\n",
    "            'title': root.find('f-title').text if root.find('f-title') is not None else '',\n",
    "            'background': {\n",
    "                'research_status': root.find('.//f-research-status').text if root.find('.//f-research-status') is not None else '',\n",
    "                'literature_map': root.find('.//f-literature-map').text if root.find('.//f-literature-map') is not None else ''\n",
    "            },\n",
    "            'gaps': [],\n",
    "            'directions': [],\n",
    "            'regional_comparison': {\n",
    "                'domestic': root.find('.//f-domestic').text if root.find('.//f-domestic') is not None else '',\n",
    "                'international': root.find('.//f-international').text if root.find('.//f-international') is not None else ''\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # è§£æç ”ç©¶ç©ºç™½\n",
    "        gaps = root.find('f-gaps')\n",
    "        if gaps is not None:\n",
    "            for gap in gaps:\n",
    "                if gap.text:\n",
    "                    framework_data['gaps'].append(gap.text.strip())\n",
    "        \n",
    "        # è§£æç ”ç©¶æ–¹å‘\n",
    "        directions = root.find('f-directions')\n",
    "        if directions is not None:\n",
    "            for direction in directions.findall('f-direction'):\n",
    "                scope = direction.find('f-scope')\n",
    "                limitations = direction.find('f-inherent-limitations')\n",
    "                framework_data['directions'].append({\n",
    "                    'scope': scope.text.strip() if scope is not None and scope.text else '',\n",
    "                    'limitations': limitations.text.strip() if limitations is not None and limitations.text else ''\n",
    "                })\n",
    "        \n",
    "        return framework_data\n",
    "    \n",
    "    def search_literature(self, query: str, context: str = \"\") -> str:\n",
    "        \"\"\"ä½¿ç”¨Kimi APIè¿›è¡Œæ–‡çŒ®æ£€ç´¢\"\"\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡çŒ®æ£€ç´¢åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æŸ¥è¯¢å†…å®¹ï¼Œæœç´¢ç›¸å…³çš„å­¦æœ¯æ–‡çŒ®å’Œç ”ç©¶èµ„æ–™ã€‚\n",
    "\n",
    "è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¿›è¡Œæ£€ç´¢å’Œæ•´ç†ï¼š\n",
    "1. æœç´¢ä¸æŸ¥è¯¢å†…å®¹ç›¸å…³çš„æœ€æ–°å­¦æœ¯æ–‡çŒ®\n",
    "2. é‡ç‚¹å…³æ³¨æƒå¨æœŸåˆŠã€ä¼šè®®è®ºæ–‡å’Œä¸“ä¸šæŠ¥å‘Š\n",
    "3. æä¾›æ–‡çŒ®çš„æ ¸å¿ƒè§‚ç‚¹å’Œä¸»è¦å‘ç°\n",
    "4. åŒ…å«ä½œè€…ä¿¡æ¯ã€å‘è¡¨å¹´ä»½ã€æœŸåˆŠ/ä¼šè®®åç§°ç­‰åŸºæœ¬ä¿¡æ¯\n",
    "5. ç”¨ä¸­æ–‡æ€»ç»“æ–‡çŒ®å†…å®¹\n",
    "\n",
    "ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{context}\n",
    "\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"è¯·æœç´¢å…³äºä»¥ä¸‹å†…å®¹çš„ç›¸å…³æ–‡çŒ®ï¼š{query}\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"builtin_function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"$web_search\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šè§¦å‘è”ç½‘æœç´¢\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                temperature=0.3,\n",
    "                stream=True\n",
    "            )\n",
    "            \n",
    "            # å¤„ç†æµå¼å“åº”\n",
    "            tool_calls = []\n",
    "            for chunk in response:\n",
    "                if chunk.choices[0].delta.tool_calls:\n",
    "                    tool_calls.extend(chunk.choices[0].delta.tool_calls)\n",
    "                \n",
    "                if chunk.choices[0].finish_reason == \"tool_calls\":\n",
    "                    break\n",
    "            \n",
    "            # å¤„ç†å·¥å…·è°ƒç”¨\n",
    "            if tool_calls:\n",
    "                tool_call = tool_calls[0]\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"\",\n",
    "                    \"tool_calls\": [tool_call]\n",
    "                })\n",
    "                \n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(tool_call.function.arguments)\n",
    "                })\n",
    "                \n",
    "                # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šè·å–æœ€ç»ˆç»“æœ\n",
    "                final_response = client.chat.completions.create(\n",
    "                    model=MODEL,\n",
    "                    messages=messages,\n",
    "                    temperature=0.3,\n",
    "                    stream=True\n",
    "                )\n",
    "                \n",
    "                full_content = \"\"\n",
    "                for chunk in final_response:\n",
    "                    if chunk.choices[0].delta.content:\n",
    "                        content = chunk.choices[0].delta.content\n",
    "                        print(content, end=\"\", flush=True)  # å®æ—¶è¾“å‡º\n",
    "                        full_content += content\n",
    "                \n",
    "                return full_content\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\næ£€ç´¢å‡ºé”™: {e}\")\n",
    "            return f\"æ£€ç´¢å¤±è´¥ï¼š{query}\"\n",
    "        \n",
    "        return \"æœªèƒ½è·å–åˆ°æœ‰æ•ˆå“åº”\"\n",
    "    \n",
    "    def extract_references_from_content(self, content: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ä»å†…å®¹ä¸­æå–å‚è€ƒæ–‡çŒ®ä¿¡æ¯\"\"\"\n",
    "        references = []\n",
    "        \n",
    "        # ç®€å•çš„å‚è€ƒæ–‡çŒ®æå–é€»è¾‘ï¼ˆå¯ä»¥æ ¹æ®å®é™…éœ€è¦æ”¹è¿›ï¼‰\n",
    "        patterns = [\n",
    "            r'([\\u4e00-\\u9fa5a-zA-Z\\s]+)\\s*\\(\\s*(\\d{4})\\s*\\)\\s*[.ã€‚]\\s*([^.ã€‚]+)[.ã€‚]\\s*([^.ã€‚]+)[.ã€‚]?',\n",
    "            r'([\\u4e00-\\u9fa5a-zA-Z\\s,]+)[.ã€‚]\\s*([^.ã€‚]+)[.ã€‚]\\s*(\\d{4})[.ã€‚]?',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, content)\n",
    "            for match in matches:\n",
    "                if len(match) >= 3:\n",
    "                    ref = {\n",
    "                        'id': str(self.reference_counter),\n",
    "                        'type': 'journal',\n",
    "                        'creators': [match[0].strip()],\n",
    "                        'title': match[2].strip() if len(match) > 2 else '',\n",
    "                        'year': match[1].strip() if len(match) > 1 else '',\n",
    "                        'publication': match[3].strip() if len(match) > 3 else ''\n",
    "                    }\n",
    "                    references.append(ref)\n",
    "                    self.references[str(self.reference_counter)] = ref\n",
    "                    self.reference_counter += 1\n",
    "        \n",
    "        return references\n",
    "    \n",
    "    def calculate_total_steps(self, framework_data: Dict[str, Any]) -> int:\n",
    "        \"\"\"è®¡ç®—æ€»çš„æ£€ç´¢æ­¥éª¤æ•°\"\"\"\n",
    "        total_steps = 0\n",
    "        \n",
    "        # ç ”ç©¶èƒŒæ™¯ï¼š2æ­¥ï¼ˆç ”ç©¶ç°çŠ¶ + æ–‡çŒ®åœ°å›¾ï¼‰\n",
    "        total_steps += 2\n",
    "        \n",
    "        # ç ”ç©¶ç©ºç™½ï¼šæ¯ä¸ªç©ºç™½1æ­¥\n",
    "        total_steps += len(framework_data['gaps'])\n",
    "        \n",
    "        # ç ”ç©¶æ–¹å‘ï¼šæ¯ä¸ªæ–¹å‘2æ­¥ï¼ˆèŒƒå›´ + å±€é™æ€§ï¼‰\n",
    "        total_steps += len(framework_data['directions']) * 2\n",
    "        \n",
    "        # å›½å†…å¤–ç ”ç©¶ï¼š2æ­¥ï¼ˆå›½å†… + å›½é™…ï¼‰\n",
    "        total_steps += 2\n",
    "        \n",
    "        return total_steps\n",
    "    \n",
    "    def generate_material_structure(self, framework_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"ç”Ÿæˆmaterialç»“æ„çš„XML\"\"\"\n",
    "        # è®¡ç®—æ€»æ­¥éª¤æ•°å¹¶åˆå§‹åŒ–è¿›åº¦æ¡\n",
    "        total_steps = self.calculate_total_steps(framework_data)\n",
    "        progress_bar = ProgressBar(total_steps)\n",
    "        \n",
    "        print(f\"ğŸš€ å¼€å§‹è¿›è¡Œæ–‡çŒ®æ£€ç´¢ï¼Œå…± {total_steps} ä¸ªæ£€ç´¢ä»»åŠ¡...\\n\")\n",
    "        \n",
    "        # æ£€ç´¢ç ”ç©¶ç°çŠ¶\n",
    "        progress_bar.update(\"æ£€ç´¢ç ”ç©¶ç°çŠ¶ç›¸å…³æ–‡çŒ®\")\n",
    "        research_status_content = self.search_literature(\n",
    "            framework_data['background']['research_status'],\n",
    "            \"ç ”ç©¶ç°çŠ¶å’ŒèƒŒæ™¯\"\n",
    "        )\n",
    "        \n",
    "        # æ£€ç´¢æ–‡çŒ®åœ°å›¾\n",
    "        progress_bar.update(\"æ£€ç´¢æ–‡çŒ®ä¸»é¢˜å…³ç³»ç›¸å…³æ–‡çŒ®\")\n",
    "        literature_map_content = self.search_literature(\n",
    "            framework_data['background']['literature_map'],\n",
    "            \"æ–‡çŒ®ä¸»é¢˜å’Œå…³ç³»\"\n",
    "        )\n",
    "        \n",
    "        # æ£€ç´¢ç ”ç©¶ç©ºç™½\n",
    "        gaps_content = []\n",
    "        for i, gap in enumerate(framework_data['gaps']):\n",
    "            progress_bar.update(f\"æ£€ç´¢ç ”ç©¶ç©ºç™½ {i+1}/{len(framework_data['gaps'])}: {gap[:50]}...\")\n",
    "            content = self.search_literature(gap, \"ç ”ç©¶ç©ºç™½å’Œä¸è¶³\")\n",
    "            gaps_content.append(content)\n",
    "        \n",
    "        # æ£€ç´¢ç ”ç©¶æ–¹å‘\n",
    "        directions_content = []\n",
    "        for i, direction in enumerate(framework_data['directions']):\n",
    "            # æ£€ç´¢æ–¹å‘èŒƒå›´\n",
    "            progress_bar.update(f\"æ£€ç´¢ç ”ç©¶æ–¹å‘ {i+1} çš„èŒƒå›´: {direction['scope'][:50]}...\")\n",
    "            scope_content = self.search_literature(direction['scope'], \"ç ”ç©¶æ–¹å‘å’ŒèŒƒå›´\")\n",
    "            \n",
    "            # æ£€ç´¢æ–¹å‘å±€é™æ€§\n",
    "            progress_bar.update(f\"æ£€ç´¢ç ”ç©¶æ–¹å‘ {i+1} çš„å±€é™æ€§: {direction['limitations'][:50]}...\")\n",
    "            limitations_content = self.search_literature(direction['limitations'], \"ç ”ç©¶å±€é™æ€§\")\n",
    "            \n",
    "            directions_content.append({\n",
    "                'scope': scope_content,\n",
    "                'limitations': limitations_content\n",
    "            })\n",
    "        \n",
    "        # æ£€ç´¢å›½å†…å¤–ç ”ç©¶\n",
    "        progress_bar.update(\"æ£€ç´¢å›½å†…ç ”ç©¶ç°çŠ¶ç›¸å…³æ–‡çŒ®\")\n",
    "        domestic_content = self.search_literature(\n",
    "            framework_data['regional_comparison']['domestic'],\n",
    "            \"å›½å†…ç ”ç©¶ç°çŠ¶\"\n",
    "        )\n",
    "        \n",
    "        progress_bar.update(\"æ£€ç´¢å›½é™…ç ”ç©¶ç°çŠ¶ç›¸å…³æ–‡çŒ®\")\n",
    "        international_content = self.search_literature(\n",
    "            framework_data['regional_comparison']['international'],\n",
    "            \"å›½é™…ç ”ç©¶ç°çŠ¶\"\n",
    "        )\n",
    "        \n",
    "        # å®Œæˆè¿›åº¦æ¡\n",
    "        progress_bar.finish()\n",
    "        \n",
    "        print(\"\\nğŸ“š å¼€å§‹æå–å‚è€ƒæ–‡çŒ®ä¿¡æ¯...\")\n",
    "        \n",
    "        # æå–æ‰€æœ‰å‚è€ƒæ–‡çŒ®\n",
    "        all_content = [research_status_content, literature_map_content] + gaps_content\n",
    "        for direction in directions_content:\n",
    "            all_content.extend([direction['scope'], direction['limitations']])\n",
    "        all_content.extend([domestic_content, international_content])\n",
    "        \n",
    "        for content in all_content:\n",
    "            self.extract_references_from_content(content)\n",
    "        \n",
    "        print(f\"âœ… å·²æå– {len(self.references)} æ¡å‚è€ƒæ–‡çŒ®\")\n",
    "        print(\"\\nğŸ”§ æ­£åœ¨ç”ŸæˆXMLç»“æ„...\")\n",
    "        \n",
    "        # ç”ŸæˆXMLç»“æ„\n",
    "        xml_content = f\"\"\"\n",
    "<material>\n",
    "  <t-chapters>\n",
    "    \n",
    "    <!-- 3. ç ”ç©¶èƒŒæ™¯ -->\n",
    "    <t-chapter id=\"c3\">\n",
    "      <t-heading>ç ”ç©¶èƒŒæ™¯</t-heading>\n",
    "      \n",
    "      <!-- 3.1 ç ”ç©¶ç°çŠ¶ -->\n",
    "      <t-section id=\"c3-s1\">\n",
    "        <t-heading>ç ”ç©¶ç°çŠ¶</t-heading>\n",
    "        <t-purpose>æœ¬èŠ‚å°†ç³»ç»Ÿæ¢³ç†{framework_data['title']}é¢†åŸŸçš„å·²æœ‰ç ”ç©¶æˆæœ</t-purpose>\n",
    "        \n",
    "        <t-point id=\"c3-s1-p1\">\n",
    "          <t-claim>{research_status_content[:200]}...</t-claim>\n",
    "          <t-keywords>ç ”ç©¶ç°çŠ¶, å‘å±•å†ç¨‹, ä¸»è¦æˆæœ</t-keywords>\n",
    "          <t-gap>éœ€è¦è¿›ä¸€æ­¥è¡¥å……æœ€æ–°ç ”ç©¶è¿›å±•</t-gap>\n",
    "        </t-point>\n",
    "        \n",
    "        <t-point id=\"c3-s1-p2\">\n",
    "          <t-claim>{literature_map_content[:200]}...</t-claim>\n",
    "          <t-keywords>æ–‡çŒ®ä¸»é¢˜, ç ”ç©¶å…³ç³», çŸ¥è¯†å›¾è°±</t-keywords>\n",
    "          <t-gap>éœ€è¦æ·±å…¥åˆ†æä¸»é¢˜é—´çš„å†…åœ¨è”ç³»</t-gap>\n",
    "        </t-point>\n",
    "        \n",
    "      </t-section>\n",
    "    </t-chapter>\n",
    "    \n",
    "    <!-- 4. å½“å‰ç ”ç©¶ä¸­å­˜åœ¨çš„é—®é¢˜å’Œä¸è¶³ -->\n",
    "    <t-chapter id=\"c4\">\n",
    "      <t-heading>å½“å‰ç ”ç©¶ä¸­å­˜åœ¨çš„é—®é¢˜å’Œä¸è¶³</t-heading>\n",
    "      \n",
    "      <t-section id=\"c4-s1\">\n",
    "        <t-heading>ä¸»è¦ç ”ç©¶ç©ºç™½</t-heading>\n",
    "\"\"\"\n",
    "        \n",
    "        # æ·»åŠ ç ”ç©¶ç©ºç™½å†…å®¹\n",
    "        for i, gap_content in enumerate(gaps_content):\n",
    "            xml_content += f\"\"\"\n",
    "        <t-point id=\"c4-s1-p{i+1}\">\n",
    "          <t-claim>{gap_content[:200]}...</t-claim>\n",
    "          <t-gap>å¾…è¿›ä¸€æ­¥æ·±å…¥ç ”ç©¶</t-gap>\n",
    "        </t-point>\n",
    "\"\"\"\n",
    "        \n",
    "        xml_content += \"\"\"\n",
    "      </t-section>\n",
    "    </t-chapter>\n",
    "    \n",
    "    <!-- 5. å½“å‰ç ”ç©¶çš„ä¸»è¦æ–¹å‘åŠå…¶ä¸è¶³ -->\n",
    "    <t-chapter id=\"c5\">\n",
    "      <t-heading>å½“å‰ç ”ç©¶çš„ä¸»è¦æ–¹å‘åŠå…¶ä¸è¶³</t-heading>\n",
    "\"\"\"\n",
    "        \n",
    "        # æ·»åŠ ç ”ç©¶æ–¹å‘å†…å®¹\n",
    "        for i, direction_content in enumerate(directions_content):\n",
    "            xml_content += f\"\"\"\n",
    "      <t-section id=\"c5-s{i+1}\">\n",
    "        <t-heading>æ–¹å‘{i+1}</t-heading>\n",
    "        <t-point id=\"c5-s{i+1}-p1\">\n",
    "          <t-claim>{direction_content['scope'][:200]}...</t-claim>\n",
    "          <t-gap>{direction_content['limitations'][:200]}...</t-gap>\n",
    "        </t-point>\n",
    "      </t-section>\n",
    "\"\"\"\n",
    "        \n",
    "        xml_content += f\"\"\"\n",
    "    </t-chapter>\n",
    "    \n",
    "    <!-- 6. å›½å†…å¤–ç›¸å…³ç ”ç©¶æ¯”è¾ƒ -->\n",
    "    <t-chapter id=\"c6\">\n",
    "      <t-heading>å›½å†…å¤–ç›¸å…³ç ”ç©¶æ¯”è¾ƒ</t-heading>\n",
    "      \n",
    "      <t-section id=\"c6-s1\">\n",
    "        <t-heading>å›½å†…ç ”ç©¶</t-heading>\n",
    "        <t-point id=\"c6-s1-p1\">\n",
    "          <t-claim>{domestic_content[:200]}...</t-claim>\n",
    "        </t-point>\n",
    "      </t-section>\n",
    "      \n",
    "      <t-section id=\"c6-s2\">\n",
    "        <t-heading>å›½å¤–ç ”ç©¶</t-heading>\n",
    "        <t-point id=\"c6-s2-p1\">\n",
    "          <t-claim>{international_content[:200]}...</t-claim>\n",
    "        </t-point>\n",
    "      </t-section>\n",
    "      \n",
    "      <t-section id=\"c6-s3\">\n",
    "        <t-heading>å·®å¼‚ä¸å¯ç¤º</t-heading>\n",
    "        <t-point id=\"c6-s3-p1\">\n",
    "          <t-claim>é€šè¿‡æ¯”è¾ƒåˆ†æï¼Œå¯ä»¥å‘ç°å›½å†…å¤–ç ”ç©¶çš„å·®å¼‚å’Œäº’è¡¥æ€§</t-claim>\n",
    "        </t-point>\n",
    "      </t-section>\n",
    "    </t-chapter>\n",
    "    \n",
    "  </t-chapters>\n",
    "  \n",
    "  <!-- å‚è€ƒæ–‡çŒ®å®¹å™¨ -->\n",
    "  <t-sources>\n",
    "\"\"\"\n",
    "        \n",
    "        # æ·»åŠ å‚è€ƒæ–‡çŒ®\n",
    "        for ref_id, ref_data in self.references.items():\n",
    "            creators_xml = '\\n'.join([f'    <t-creator>{creator}</t-creator>' for creator in ref_data['creators']])\n",
    "            xml_content += f\"\"\"\n",
    "    <t-ref id=\"{ref_id}\" type=\"{ref_data['type']}\">\n",
    "{creators_xml}\n",
    "      <t-title>{ref_data['title']}</t-title>\n",
    "      <t-publication>\n",
    "        <t-publisher>{ref_data['publication']}</t-publisher>\n",
    "        <t-year>{ref_data['year']}</t-year>\n",
    "      </t-publication>\n",
    "    </t-ref>\n",
    "\"\"\"\n",
    "        \n",
    "        xml_content += \"\"\"\n",
    "  </t-sources>\n",
    "</material>\n",
    "\"\"\"\n",
    "        \n",
    "        return xml_content\n",
    "    \n",
    "    def process_framework(self, framework_path: str, output_path: str = None):\n",
    "        \"\"\"å¤„ç†æ•´ä¸ªæ¡†æ¶ï¼Œç”Ÿæˆmaterialç»“æ„\"\"\"\n",
    "        print(f\"ğŸ“– å¼€å§‹å¤„ç†æ¡†æ¶æ–‡ä»¶: {framework_path}\")\n",
    "        \n",
    "        # è§£ææ¡†æ¶\n",
    "        framework_data = self.parse_framework(framework_path)\n",
    "        print(f\"âœ… æ¡†æ¶è§£æå®Œæˆï¼Œæ ‡é¢˜: {framework_data['title']}\")\n",
    "        \n",
    "        # ç”Ÿæˆmaterialç»“æ„\n",
    "        material_xml = self.generate_material_structure(framework_data)\n",
    "        \n",
    "        # ä¿å­˜ç»“æœ\n",
    "        if output_path is None:\n",
    "            output_path = \"material.xml\"\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(material_xml)\n",
    "        \n",
    "        print(f\"\\nğŸ‰ å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_path}\")\n",
    "        return material_xml\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "if __name__ == \"__main__\":\n",
    "    processor = FrameworkProcessor()\n",
    "    \n",
    "    # å¤„ç†framework.xmlæ–‡ä»¶\n",
    "    framework_path = \"framework.xml\"\n",
    "    output_path = \"material-2.xml\"\n",
    "    \n",
    "    try:\n",
    "        result = processor.process_framework(framework_path, output_path)\n",
    "        print(\"\\n=== ğŸŠ æ‰€æœ‰ä»»åŠ¡å®Œæˆ ===\")\n",
    "        print(f\"ğŸ“„ ç”Ÿæˆçš„materialç»“æ„å·²ä¿å­˜åˆ°: {output_path}\")\n",
    "        print(f\"ğŸ“š å…±æå–äº† {len(processor.references)} æ¡å‚è€ƒæ–‡çŒ®\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
