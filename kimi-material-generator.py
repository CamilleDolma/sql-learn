import xml.etree.ElementTree as ET
import json
import os
from openai import OpenAI
from typing import Dict, List, Any
import re
import sys
import time

# è®¾ç½®å®¢æˆ·ç«¯
client = OpenAI(
    api_key="sk-ngwOcq4h7reY7qL7jQeOVkmZhWCg9Xh95ilq2NkXIsArpQRC",
    base_url="https://api.moonshot.cn/v1"
)

MODEL = "kimi-k2-0711-preview"

class ProgressBar:
    def __init__(self, total_steps: int, width: int = 50):
        self.total_steps = total_steps
        self.current_step = 0
        self.width = width
        self.start_time = time.time()
        
    def update(self, step_description: str = ""):
        """æ›´æ–°è¿›åº¦æ¡"""
        self.current_step += 1
        progress = self.current_step / self.total_steps
        filled_width = int(self.width * progress)
        
        # è®¡ç®—å·²ç”¨æ—¶é—´å’Œé¢„ä¼°å‰©ä½™æ—¶é—´
        elapsed_time = time.time() - self.start_time
        if self.current_step > 0:
            avg_time_per_step = elapsed_time / self.current_step
            remaining_steps = self.total_steps - self.current_step
            eta = avg_time_per_step * remaining_steps
        else:
            eta = 0
            
        # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
        def format_time(seconds):
            if seconds < 60:
                return f"{seconds:.0f}s"
            elif seconds < 3600:
                return f"{seconds//60:.0f}m{seconds%60:.0f}s"
            else:
                return f"{seconds//3600:.0f}h{(seconds%3600)//60:.0f}m"
        
        # æ„å»ºè¿›åº¦æ¡
        bar = 'â–ˆ' * filled_width + 'â–‘' * (self.width - filled_width)
        percentage = progress * 100
        
        # æ¸…é™¤å½“å‰è¡Œå¹¶æ‰“å°æ–°çš„è¿›åº¦æ¡
        sys.stdout.write('\r')
        sys.stdout.write(f'è¿›åº¦: [{bar}] {percentage:.1f}% ({self.current_step}/{self.total_steps}) ')
        sys.stdout.write(f'ç”¨æ—¶: {format_time(elapsed_time)} ')
        if eta > 0:
            sys.stdout.write(f'å‰©ä½™: {format_time(eta)} ')
        if step_description:
            sys.stdout.write(f'\nå½“å‰ä»»åŠ¡: {step_description}')
        sys.stdout.flush()
        
    def finish(self):
        """å®Œæˆè¿›åº¦æ¡"""
        total_time = time.time() - self.start_time
        sys.stdout.write('\n')
        print(f"âœ… æ‰€æœ‰æ£€ç´¢ä»»åŠ¡å®Œæˆï¼æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")

class FrameworkProcessor:
    def __init__(self):
        self.reference_counter = 1
        self.references = {}
        
    def parse_framework(self, framework_path: str) -> Dict[str, Any]:
        """è§£æframework.xmlæ–‡ä»¶"""
        tree = ET.parse(framework_path)
        root = tree.getroot()
        
        framework_data = {
            'title': root.find('f-title').text if root.find('f-title') is not None else '',
            'background': {
                'research_status': root.find('.//f-research-status').text if root.find('.//f-research-status') is not None else '',
                'literature_map': root.find('.//f-literature-map').text if root.find('.//f-literature-map') is not None else ''
            },
            'gaps': [],
            'directions': [],
            'regional_comparison': {
                'domestic': root.find('.//f-domestic').text if root.find('.//f-domestic') is not None else '',
                'international': root.find('.//f-international').text if root.find('.//f-international') is not None else ''
            }
        }
        
        # è§£æç ”ç©¶ç©ºç™½
        gaps = root.find('f-gaps')
        if gaps is not None:
            for gap in gaps:
                if gap.text:
                    framework_data['gaps'].append(gap.text.strip())
        
        # è§£æç ”ç©¶æ–¹å‘
        directions = root.find('f-directions')
        if directions is not None:
            for direction in directions.findall('f-direction'):
                scope = direction.find('f-scope')
                limitations = direction.find('f-inherent-limitations')
                framework_data['directions'].append({
                    'scope': scope.text.strip() if scope is not None and scope.text else '',
                    'limitations': limitations.text.strip() if limitations is not None and limitations.text else ''
                })
        
        return framework_data
    
    def search_literature(self, query: str, context: str = "") -> str:
        """ä½¿ç”¨Kimi APIè¿›è¡Œæ–‡çŒ®æ£€ç´¢"""
        messages = [
            {
                "role": "system",
                "content": f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡çŒ®æ£€ç´¢åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æŸ¥è¯¢å†…å®¹ï¼Œæœç´¢ç›¸å…³çš„å­¦æœ¯æ–‡çŒ®å’Œç ”ç©¶èµ„æ–™ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¿›è¡Œæ£€ç´¢å’Œæ•´ç†ï¼š
1. æœç´¢ä¸æŸ¥è¯¢å†…å®¹ç›¸å…³çš„æœ€æ–°å­¦æœ¯æ–‡çŒ®
2. é‡ç‚¹å…³æ³¨æƒå¨æœŸåˆŠã€ä¼šè®®è®ºæ–‡å’Œä¸“ä¸šæŠ¥å‘Š
3. æä¾›æ–‡çŒ®çš„æ ¸å¿ƒè§‚ç‚¹å’Œä¸»è¦å‘ç°
4. åŒ…å«ä½œè€…ä¿¡æ¯ã€å‘è¡¨å¹´ä»½ã€æœŸåˆŠ/ä¼šè®®åç§°ç­‰åŸºæœ¬ä¿¡æ¯
5. ç”¨ä¸­æ–‡æ€»ç»“æ–‡çŒ®å†…å®¹

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{context}
"""
            },
            {
                "role": "user",
                "content": f"è¯·æœç´¢å…³äºä»¥ä¸‹å†…å®¹çš„ç›¸å…³æ–‡çŒ®ï¼š{query}"
            }
        ]
        
        tools = [
            {
                "type": "builtin_function",
                "function": {
                    "name": "$web_search"
                }
            }
        ]
        
        try:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šè§¦å‘è”ç½‘æœç´¢
            response = client.chat.completions.create(
                model=MODEL,
                messages=messages,
                tools=tools,
                temperature=0.3,
                stream=True
            )
            
            # å¤„ç†æµå¼å“åº”
            tool_calls = []
            for chunk in response:
                if chunk.choices[0].delta.tool_calls:
                    tool_calls.extend(chunk.choices[0].delta.tool_calls)
                
                if chunk.choices[0].finish_reason == "tool_calls":
                    break
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if tool_calls:
                tool_call = tool_calls[0]
                messages.append({
                    "role": "assistant",
                    "content": "",
                    "tool_calls": [tool_call]
                })
                
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(tool_call.function.arguments)
                })
                
                # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šè·å–æœ€ç»ˆç»“æœ
                final_response = client.chat.completions.create(
                    model=MODEL,
                    messages=messages,
                    temperature=0.3,
                    stream=True
                )
                
                full_content = ""
                for chunk in final_response:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        print(content, end="", flush=True)  # å®æ—¶è¾“å‡º
                        full_content += content
                
                return full_content
            
        except Exception as e:
            print(f"\næ£€ç´¢å‡ºé”™: {e}")
            return f"æ£€ç´¢å¤±è´¥ï¼š{query}"
        
        return "æœªèƒ½è·å–åˆ°æœ‰æ•ˆå“åº”"
    
    def extract_references_from_content(self, content: str) -> List[Dict[str, Any]]:
        """ä»å†…å®¹ä¸­æå–å‚è€ƒæ–‡çŒ®ä¿¡æ¯"""
        references = []
        
        # ç®€å•çš„å‚è€ƒæ–‡çŒ®æå–é€»è¾‘ï¼ˆå¯ä»¥æ ¹æ®å®é™…éœ€è¦æ”¹è¿›ï¼‰
        patterns = [
            r'([\u4e00-\u9fa5a-zA-Z\s]+)\s*\(\s*(\d{4})\s*\)\s*[.ã€‚]\s*([^.ã€‚]+)[.ã€‚]\s*([^.ã€‚]+)[.ã€‚]?',
            r'([\u4e00-\u9fa5a-zA-Z\s,]+)[.ã€‚]\s*([^.ã€‚]+)[.ã€‚]\s*(\d{4})[.ã€‚]?',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                if len(match) >= 3:
                    ref = {
                        'id': str(self.reference_counter),
                        'type': 'journal',
                        'creators': [match[0].strip()],
                        'title': match[2].strip() if len(match) > 2 else '',
                        'year': match[1].strip() if len(match) > 1 else '',
                        'publication': match[3].strip() if len(match) > 3 else ''
                    }
                    references.append(ref)
                    self.references[str(self.reference_counter)] = ref
                    self.reference_counter += 1
        
        return references
    
    def calculate_total_steps(self, framework_data: Dict[str, Any]) -> int:
        """è®¡ç®—æ€»çš„æ£€ç´¢æ­¥éª¤æ•°"""
        total_steps = 0
        
        # ç ”ç©¶èƒŒæ™¯ï¼š2æ­¥ï¼ˆç ”ç©¶ç°çŠ¶ + æ–‡çŒ®åœ°å›¾ï¼‰
        total_steps += 2
        
        # ç ”ç©¶ç©ºç™½ï¼šæ¯ä¸ªç©ºç™½1æ­¥
        total_steps += len(framework_data['gaps'])
        
        # ç ”ç©¶æ–¹å‘ï¼šæ¯ä¸ªæ–¹å‘2æ­¥ï¼ˆèŒƒå›´ + å±€é™æ€§ï¼‰
        total_steps += len(framework_data['directions']) * 2
        
        # å›½å†…å¤–ç ”ç©¶ï¼š2æ­¥ï¼ˆå›½å†… + å›½é™…ï¼‰
        total_steps += 2
        
        return total_steps
    
    def generate_material_structure(self, framework_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆmaterialç»“æ„çš„XML"""
        # è®¡ç®—æ€»æ­¥éª¤æ•°å¹¶åˆå§‹åŒ–è¿›åº¦æ¡
        total_steps = self.calculate_total_steps(framework_data)
        progress_bar = ProgressBar(total_steps)
        
        print(f"ğŸš€ å¼€å§‹è¿›è¡Œæ–‡çŒ®æ£€ç´¢ï¼Œå…± {total_steps} ä¸ªæ£€ç´¢ä»»åŠ¡...\n")
        
        # æ£€ç´¢ç ”ç©¶ç°çŠ¶
        progress_bar.update("æ£€ç´¢ç ”ç©¶ç°çŠ¶ç›¸å…³æ–‡çŒ®")
        research_status_content = self.search_literature(
            framework_data['background']['research_status'],
            "ç ”ç©¶ç°çŠ¶å’ŒèƒŒæ™¯"
        )
        
        # æ£€ç´¢æ–‡çŒ®åœ°å›¾
        progress_bar.update("æ£€ç´¢æ–‡çŒ®ä¸»é¢˜å…³ç³»ç›¸å…³æ–‡çŒ®")
        literature_map_content = self.search_literature(
            framework_data['background']['literature_map'],
            "æ–‡çŒ®ä¸»é¢˜å’Œå…³ç³»"
        )
        
        # æ£€ç´¢ç ”ç©¶ç©ºç™½
        gaps_content = []
        for i, gap in enumerate(framework_data['gaps']):
            progress_bar.update(f"æ£€ç´¢ç ”ç©¶ç©ºç™½ {i+1}/{len(framework_data['gaps'])}: {gap[:50]}...")
            content = self.search_literature(gap, "ç ”ç©¶ç©ºç™½å’Œä¸è¶³")
            gaps_content.append(content)
        
        # æ£€ç´¢ç ”ç©¶æ–¹å‘
        directions_content = []
        for i, direction in enumerate(framework_data['directions']):
            # æ£€ç´¢æ–¹å‘èŒƒå›´
            progress_bar.update(f"æ£€ç´¢ç ”ç©¶æ–¹å‘ {i+1} çš„èŒƒå›´: {direction['scope'][:50]}...")
            scope_content = self.search_literature(direction['scope'], "ç ”ç©¶æ–¹å‘å’ŒèŒƒå›´")
            
            # æ£€ç´¢æ–¹å‘å±€é™æ€§
            progress_bar.update(f"æ£€ç´¢ç ”ç©¶æ–¹å‘ {i+1} çš„å±€é™æ€§: {direction['limitations'][:50]}...")
            limitations_content = self.search_literature(direction['limitations'], "ç ”ç©¶å±€é™æ€§")
            
            directions_content.append({
                'scope': scope_content,
                'limitations': limitations_content
            })
        
        # æ£€ç´¢å›½å†…å¤–ç ”ç©¶
        progress_bar.update("æ£€ç´¢å›½å†…ç ”ç©¶ç°çŠ¶ç›¸å…³æ–‡çŒ®")
        domestic_content = self.search_literature(
            framework_data['regional_comparison']['domestic'],
            "å›½å†…ç ”ç©¶ç°çŠ¶"
        )
        
        progress_bar.update("æ£€ç´¢å›½é™…ç ”ç©¶ç°çŠ¶ç›¸å…³æ–‡çŒ®")
        international_content = self.search_literature(
            framework_data['regional_comparison']['international'],
            "å›½é™…ç ”ç©¶ç°çŠ¶"
        )
        
        # å®Œæˆè¿›åº¦æ¡
        progress_bar.finish()
        
        print("\nğŸ“š å¼€å§‹æå–å‚è€ƒæ–‡çŒ®ä¿¡æ¯...")
        
        # æå–æ‰€æœ‰å‚è€ƒæ–‡çŒ®
        all_content = [research_status_content, literature_map_content] + gaps_content
        for direction in directions_content:
            all_content.extend([direction['scope'], direction['limitations']])
        all_content.extend([domestic_content, international_content])
        
        for content in all_content:
            self.extract_references_from_content(content)
        
        print(f"âœ… å·²æå– {len(self.references)} æ¡å‚è€ƒæ–‡çŒ®")
        print("\nğŸ”§ æ­£åœ¨ç”ŸæˆXMLç»“æ„...")
        
        # ç”ŸæˆXMLç»“æ„
        xml_content = f"""
<material>
  <t-chapters>
    
    <!-- 3. ç ”ç©¶èƒŒæ™¯ -->
    <t-chapter id="c3">
      <t-heading>ç ”ç©¶èƒŒæ™¯</t-heading>
      
      <!-- 3.1 ç ”ç©¶ç°çŠ¶ -->
      <t-section id="c3-s1">
        <t-heading>ç ”ç©¶ç°çŠ¶</t-heading>
        <t-purpose>æœ¬èŠ‚å°†ç³»ç»Ÿæ¢³ç†{framework_data['title']}é¢†åŸŸçš„å·²æœ‰ç ”ç©¶æˆæœ</t-purpose>
        
        <t-point id="c3-s1-p1">
          <t-claim>{research_status_content[:200]}...</t-claim>
          <t-keywords>ç ”ç©¶ç°çŠ¶, å‘å±•å†ç¨‹, ä¸»è¦æˆæœ</t-keywords>
          <t-gap>éœ€è¦è¿›ä¸€æ­¥è¡¥å……æœ€æ–°ç ”ç©¶è¿›å±•</t-gap>
        </t-point>
        
        <t-point id="c3-s1-p2">
          <t-claim>{literature_map_content[:200]}...</t-claim>
          <t-keywords>æ–‡çŒ®ä¸»é¢˜, ç ”ç©¶å…³ç³», çŸ¥è¯†å›¾è°±</t-keywords>
          <t-gap>éœ€è¦æ·±å…¥åˆ†æä¸»é¢˜é—´çš„å†…åœ¨è”ç³»</t-gap>
        </t-point>
        
      </t-section>
    </t-chapter>
    
    <!-- 4. å½“å‰ç ”ç©¶ä¸­å­˜åœ¨çš„é—®é¢˜å’Œä¸è¶³ -->
    <t-chapter id="c4">
      <t-heading>å½“å‰ç ”ç©¶ä¸­å­˜åœ¨çš„é—®é¢˜å’Œä¸è¶³</t-heading>
      
      <t-section id="c4-s1">
        <t-heading>ä¸»è¦ç ”ç©¶ç©ºç™½</t-heading>
"""
        
        # æ·»åŠ ç ”ç©¶ç©ºç™½å†…å®¹
        for i, gap_content in enumerate(gaps_content):
            xml_content += f"""
        <t-point id="c4-s1-p{i+1}">
          <t-claim>{gap_content[:200]}...</t-claim>
          <t-gap>å¾…è¿›ä¸€æ­¥æ·±å…¥ç ”ç©¶</t-gap>
        </t-point>
"""
        
        xml_content += """
      </t-section>
    </t-chapter>
    
    <!-- 5. å½“å‰ç ”ç©¶çš„ä¸»è¦æ–¹å‘åŠå…¶ä¸è¶³ -->
    <t-chapter id="c5">
      <t-heading>å½“å‰ç ”ç©¶çš„ä¸»è¦æ–¹å‘åŠå…¶ä¸è¶³</t-heading>
"""
        
        # æ·»åŠ ç ”ç©¶æ–¹å‘å†…å®¹
        for i, direction_content in enumerate(directions_content):
            xml_content += f"""
      <t-section id="c5-s{i+1}">
        <t-heading>æ–¹å‘{i+1}</t-heading>
        <t-point id="c5-s{i+1}-p1">
          <t-claim>{direction_content['scope'][:200]}...</t-claim>
          <t-gap>{direction_content['limitations'][:200]}...</t-gap>
        </t-point>
      </t-section>
"""
        
        xml_content += f"""
    </t-chapter>
    
    <!-- 6. å›½å†…å¤–ç›¸å…³ç ”ç©¶æ¯”è¾ƒ -->
    <t-chapter id="c6">
      <t-heading>å›½å†…å¤–ç›¸å…³ç ”ç©¶æ¯”è¾ƒ</t-heading>
      
      <t-section id="c6-s1">
        <t-heading>å›½å†…ç ”ç©¶</t-heading>
        <t-point id="c6-s1-p1">
          <t-claim>{domestic_content[:200]}...</t-claim>
        </t-point>
      </t-section>
      
      <t-section id="c6-s2">
        <t-heading>å›½å¤–ç ”ç©¶</t-heading>
        <t-point id="c6-s2-p1">
          <t-claim>{international_content[:200]}...</t-claim>
        </t-point>
      </t-section>
      
      <t-section id="c6-s3">
        <t-heading>å·®å¼‚ä¸å¯ç¤º</t-heading>
        <t-point id="c6-s3-p1">
          <t-claim>é€šè¿‡æ¯”è¾ƒåˆ†æï¼Œå¯ä»¥å‘ç°å›½å†…å¤–ç ”ç©¶çš„å·®å¼‚å’Œäº’è¡¥æ€§</t-claim>
        </t-point>
      </t-section>
    </t-chapter>
    
  </t-chapters>
  
  <!-- å‚è€ƒæ–‡çŒ®å®¹å™¨ -->
  <t-sources>
"""
        
        # æ·»åŠ å‚è€ƒæ–‡çŒ®
        for ref_id, ref_data in self.references.items():
            creators_xml = '\n'.join([f'    <t-creator>{creator}</t-creator>' for creator in ref_data['creators']])
            xml_content += f"""
    <t-ref id="{ref_id}" type="{ref_data['type']}">
{creators_xml}
      <t-title>{ref_data['title']}</t-title>
      <t-publication>
        <t-publisher>{ref_data['publication']}</t-publisher>
        <t-year>{ref_data['year']}</t-year>
      </t-publication>
    </t-ref>
"""
        
        xml_content += """
  </t-sources>
</material>
"""
        
        return xml_content
    
    def process_framework(self, framework_path: str, output_path: str = None):
        """å¤„ç†æ•´ä¸ªæ¡†æ¶ï¼Œç”Ÿæˆmaterialç»“æ„"""
        print(f"ğŸ“– å¼€å§‹å¤„ç†æ¡†æ¶æ–‡ä»¶: {framework_path}")
        
        # è§£ææ¡†æ¶
        framework_data = self.parse_framework(framework_path)
        print(f"âœ… æ¡†æ¶è§£æå®Œæˆï¼Œæ ‡é¢˜: {framework_data['title']}")
        
        # ç”Ÿæˆmaterialç»“æ„
        material_xml = self.generate_material_structure(framework_data)
        
        # ä¿å­˜ç»“æœ
        if output_path is None:
            output_path = "material.xml"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(material_xml)
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return material_xml

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    processor = FrameworkProcessor()
    
    # å¤„ç†framework.xmlæ–‡ä»¶
    framework_path = "framework.xml"
    output_path = "material-2.xml"
    
    try:
        result = processor.process_framework(framework_path, output_path)
        print("\n=== ğŸŠ æ‰€æœ‰ä»»åŠ¡å®Œæˆ ===")
        print(f"ğŸ“„ ç”Ÿæˆçš„materialç»“æ„å·²ä¿å­˜åˆ°: {output_path}")
        print(f"ğŸ“š å…±æå–äº† {len(processor.references)} æ¡å‚è€ƒæ–‡çŒ®")
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")